{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf26c81b",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Preprocessing to handle all data from the main survey (not prescreen):\n",
    "- survey data\n",
    "- Amazon data\n",
    "\n",
    ".. from both the major survey (v0) & v-cloudresearch surveys...\n",
    "\n",
    "#### Background\n",
    "\n",
    "- v0: survey v0 was initially used in mturk and then moved to Prolific. Prolific was the platform used for the large majority of responses\n",
    "    - survey responses collected from\n",
    "- v-cloudresearch: \n",
    "    - The v0 survey was copied to v-cloudresearch, used on the cloudresearch platform. \n",
    "    - The survey questions are the same as v0. \n",
    "    - The only difference is the mechanics of collecting worker IDs and routing them back to the platform. \n",
    "    - This survey was only used at the end of data collection\n",
    "    - There are 2 cloudresearch platform products used: mturk toolkit vs connect. This results in worker IDs that look different. The embedded data field \"connect\" indicates if the worker came from connect.\n",
    "- 2 surveys?\n",
    "    - The prolific sample pool was not large enough so we copied the survey to another version used in cloudresearch\n",
    "    - Note some workers work on both Prolific and Cloudresearch -- making data deduplication extra necessary\n",
    "\n",
    "## Data inputs and outputs\n",
    "\n",
    "### Output of preprocessing\n",
    "\n",
    "\n",
    "#### Survey data\n",
    "survey-data.csv\n",
    "\n",
    "Cleaned version of survey data\n",
    "- Publicly available\n",
    "- Cleaned to only include relevant fields\n",
    "- Removed worker IDs (privacy/COUHES compliance)\n",
    "- Removed comments (privacy/COUHES compliance)\n",
    "- Filtered to:\n",
    "    - only participants who passed attention check\n",
    "    - duplicate responses removed\n",
    "\n",
    "#### Amazon data\n",
    "amazon-data.csv\n",
    "\n",
    "Cleaned version of Amazon data\n",
    "- one file, where Survey ResponseId field can be used to join with survey data\n",
    "\n",
    "\n",
    "### Input data\n",
    "\n",
    "Survey data: \n",
    "- Downloaded from Qualtrics filtered to only include successful responses: completed & __passed the attention check__\n",
    "- Excluding fields:\n",
    "    - Qualtrics metadata (end time, lat,lon, IP address, etc)\n",
    "    - Error case related fields -- not relevant for data analysis or participants who successfully completed\n",
    "    - Embedded data used for survey logic (hidden file field, API token, etc)\n",
    "    - Embedded data fields used for platform integration\n",
    "\n",
    "- [Link to input data before preprocessing](https://docs.google.com/spreadsheets/d/13s_z089Im7m22uxC7dVSG5EYOymiIyvsE3RXeWal8ck/edit#gid=914929233) (requires access/share request)\n",
    "\n",
    "Amazon data:\n",
    "- All data downloaded from Qualtrics\n",
    "\n",
    "\n",
    "### Preprocessing steps\n",
    "\n",
    "1. Clean + Deduplicate Amazon data → Intermediary outputs: bad ResponseIds; cleaner Amazon data\n",
    "- Make a merged and clean data frame\n",
    "    - handle prices: \n",
    "        - drop any rows with null or non-positive price or quantity\n",
    "        - prices mapped to floats\n",
    "    - handle states:\n",
    "        - state names mapped to consistent set (data contains state names both spelled out and abbreviated, with differing casing)\n",
    "        - drop data rows for items shipped outside US\n",
    "    - handle dates:\n",
    "        - dates mapped to consistent format\n",
    "        - drop rows for dates before Jan 2018\n",
    "\n",
    "- Deduplicate: \n",
    "    - use initial rows of data from jan 2018\n",
    "    - Find # of dupes\n",
    "    - Drop duplicates. How to choose which to drop vs keep? Keep version with the most rows that have no nan values (they completed survey later or data processed/downloaded with more success).\n",
    "    - Collect response ids for duplicates to drop from both Amazon and survey data → output: drop ResponseIds\n",
    "\n",
    "2. Process survey data → Output: processed survey data (can be used on its own)\n",
    "- Deduplicate on worker/Prolific IDs\n",
    "- Join the 2 survey datasets\n",
    "- Remove data where 'test' is indicated\n",
    "- Remove rows with bad ResponseIds (from step 1)\n",
    "- Make public\n",
    "    - separate comments\n",
    "    - remove worker/Prolific IDs\n",
    "\n",
    "3. Finish Amazon data preprocessing → Output: cleaned Amazon data\n",
    "- Exclude rows without a ResponseId in survey data\n",
    "- Keep for internal use for now\n",
    "\n",
    "\n",
    "### Notes from the process\n",
    "\n",
    "- There are data for (66) response ids where there is no valid US state associated with any of their purchases. These response ids are kept. \n",
    "    - Note the possible reason for no state: shipped outside the US, nan value because delivered to locker or digital good (e.g. gift card, software)\n",
    "    \n",
    "- During process of deduping found that sometimes items were recategorized. E.g. early version of data had category = HOME; later version THERMOMETER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f681c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "358a1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the bad Response Ids to remove from data\n",
    "drop_responseids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dba7b",
   "metadata": {},
   "source": [
    "### Process Amazon data\n",
    "\n",
    "1. Clean + Deduplicate Amazon data → Intermediary outputs: drop ResponseIds; cleaner Amazon data\n",
    "- Make a merged and clean data frame\n",
    "\n",
    "- Deduplicate: \n",
    "    - use initial rows of data from jan 2018\n",
    "    - Record ResponseIds for dupes to remove from survey data → output: bad ResponseIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe4b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4645 v0 files\n",
      "612 v-cloudresearch files\n",
      "5257 total files to read\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/amazon-data/unprocessed/v0/R_hrzkhELGx5jezT7_R_3I9Pu8iauEcOx9A.csv',\n",
       " '../data/amazon-data/unprocessed/v0/R_c2JhEelp5x2LnDO_R_7UtikIBqeQHvnyN.csv',\n",
       " '../data/amazon-data/unprocessed/v0/R_9kK8zHlub96lJvk_R_2PpVNZupgA2k9mX.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the filepaths\n",
    "\n",
    "amzn_input_v0_fpath = r'../data/amazon-data/unprocessed/v0/'\n",
    "amzn_input_vcloudresearch_fpath = r'../data/amazon-data/unprocessed/v-cloudresearch/'\n",
    "amzn_input_v0_fnames = [amzn_input_v0_fpath+f for f in os.listdir(amzn_input_v0_fpath) if f.endswith('.csv')]\n",
    "amzn_input_vcloudresearch_fnames = [amzn_input_vcloudresearch_fpath+f for f in os.listdir(amzn_input_vcloudresearch_fpath) if f.endswith('.csv')]\n",
    "print('%s v0 files' % len(amzn_input_v0_fnames))\n",
    "print('%s v-cloudresearch files' % len(amzn_input_vcloudresearch_fnames))\n",
    "amzn_input_fnames = amzn_input_v0_fnames + amzn_input_vcloudresearch_fnames\n",
    "print('%s total files to read' % len(amzn_input_fnames))\n",
    "amzn_input_fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bab1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_price_float(unit_price):\n",
    "    try:\n",
    "        return float(unit_price.strip('$').replace(',',''))\n",
    "    except Exception as e:\n",
    "        #print('Exception:', e, 'for:', unit_price)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9cb5c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Order Date has multiple formats\n",
    "# Weird ones found: 03-Jun-18, 2001/4/18\n",
    "def parse_date(text):\n",
    "    \"\"\"Parses date or returns nan\"\"\"\n",
    "    text = str(text)\n",
    "    for fmt in ('%m/%d/%y', '%m/%d/%Y', '%d-%b-%y'):\n",
    "        try:\n",
    "            return datetime.strptime(text, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    print('no valid date format found for %s' % text)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5e3bde4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:29:49.138948: reading file 0 - 0 files used; 0 total purchases\n",
      "2023-04-20 11:29:53.018147: reading file 500 - 500 files used; 174675 total purchases\n",
      "2023-04-20 11:30:01.617452: reading file 1000 - 1000 files used; 379981 total purchases\n",
      "2023-04-20 11:30:15.309829: reading file 1500 - 1500 files used; 564092 total purchases\n",
      "2023-04-20 11:30:32.709280: reading file 2000 - 2000 files used; 753235 total purchases\n",
      "2023-04-20 11:30:54.594418: reading file 2500 - 2500 files used; 935331 total purchases\n",
      "2023-04-20 11:31:20.846200: reading file 3000 - 3000 files used; 1116055 total purchases\n",
      "2023-04-20 11:31:51.503982: reading file 3500 - 3500 files used; 1288570 total purchases\n",
      "2023-04-20 11:32:27.547795: reading file 4000 - 4000 files used; 1472125 total purchases\n",
      "no valid date format found for nan\n",
      "Found 1 rows with null Order Date\n",
      "2023-04-20 11:33:07.707788: reading file 4500 - 4500 files used; 1645908 total purchases\n",
      "no valid date format found for 2001/4/18\n",
      "no valid date format found for 2002/12/18\n",
      "no valid date format found for 2004/1/18\n",
      "no valid date format found for 2004/1/18\n",
      "no valid date format found for 2006/12/18\n",
      "no valid date format found for 2007/2/18\n",
      "no valid date format found for 2008/6/18\n",
      "no valid date format found for 2009/5/18\n",
      "no valid date format found for 2011/4/18\n",
      "no valid date format found for 2011/4/18\n",
      "no valid date format found for 2001/12/19\n",
      "no valid date format found for 2004/3/19\n",
      "no valid date format found for 2004/3/19\n",
      "no valid date format found for 2007/3/19\n",
      "no valid date format found for 2007/4/19\n",
      "no valid date format found for 2007/4/19\n",
      "no valid date format found for 2002/9/20\n",
      "no valid date format found for 2002/9/20\n",
      "no valid date format found for 2002/9/20\n",
      "no valid date format found for 2003/4/20\n",
      "no valid date format found for 2006/2/20\n",
      "no valid date format found for 2006/2/20\n",
      "no valid date format found for 2006/8/20\n",
      "no valid date format found for 2007/1/20\n",
      "no valid date format found for 2010/4/20\n",
      "no valid date format found for 2010/5/20\n",
      "no valid date format found for 2010/5/20\n",
      "no valid date format found for 2010/6/20\n",
      "no valid date format found for 2011/11/20\n",
      "no valid date format found for 2001/4/21\n",
      "no valid date format found for 2001/4/21\n",
      "no valid date format found for 2001/4/21\n",
      "no valid date format found for 2001/4/21\n",
      "no valid date format found for 2001/5/21\n",
      "no valid date format found for 2001/5/21\n",
      "no valid date format found for 2001/5/21\n",
      "no valid date format found for 2001/6/21\n",
      "no valid date format found for 2001/7/21\n",
      "no valid date format found for 2001/11/21\n",
      "no valid date format found for 2003/3/21\n",
      "no valid date format found for 2003/3/21\n",
      "no valid date format found for 2003/8/21\n",
      "no valid date format found for 2006/8/21\n",
      "no valid date format found for 2007/3/21\n",
      "no valid date format found for 2009/11/21\n",
      "no valid date format found for 2001/1/22\n",
      "no valid date format found for 2001/1/22\n",
      "no valid date format found for 2003/6/22\n",
      "no valid date format found for 2003/6/22\n",
      "no valid date format found for 2003/9/22\n",
      "no valid date format found for 2004/3/22\n",
      "no valid date format found for 2004/3/22\n",
      "no valid date format found for 2004/12/22\n",
      "no valid date format found for 2005/2/22\n",
      "no valid date format found for 2005/2/22\n",
      "no valid date format found for 2005/10/22\n",
      "no valid date format found for 2006/7/22\n",
      "no valid date format found for 2006/10/22\n",
      "no valid date format found for 2007/5/22\n",
      "no valid date format found for 2007/10/22\n",
      "no valid date format found for 2012/5/22\n",
      "no valid date format found for 2012/5/22\n",
      "no valid date format found for 2012/5/22\n",
      "no valid date format found for 2012/6/22\n",
      "no valid date format found for 2012/7/22\n",
      "no valid date format found for 2002/1/23\n",
      "no valid date format found for 2002/9/23\n",
      "no valid date format found for 2003/6/23\n",
      "Found 68 rows with null Order Date\n",
      "2023-04-20 11:33:52.877434: reading file 5000 - 5000 files used; 1838907 total purchases\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Make a giant data frame:\n",
    "- map date to consistent format\n",
    "- drop any rows with null or non-positive price or quantity\n",
    "- drop rows before 2018-01-01\n",
    "- prices mapped to floats\n",
    "- dates mapped to yyyy-mm\n",
    "\"\"\"\n",
    "\n",
    "files_used = 0\n",
    "amzn_df = pd.DataFrame()\n",
    "\n",
    "for i, f in enumerate(amzn_input_fnames):\n",
    "    if i%500 == 0:\n",
    "        print('%s: reading file %s - %s files used; %s total purchases' % \n",
    "              (pd.Timestamp.now(), i, files_used, len(amzn_df)))\n",
    "    df = pd.read_csv(f)\n",
    "    files_used += 1\n",
    "    # Handle dates\n",
    "    df['Order Date'] = df['Order Date'].apply(parse_date)\n",
    "    if len(df[df['Order Date'].isna()]) > 0:\n",
    "        print('Found %s rows with null Order Date' % len(df[df['Order Date'].isna()]))\n",
    "        df = df[df['Order Date'].notna()]   \n",
    "    # Drop rows before 1-1-2018 \n",
    "    df = df[df['Order Date'] >= pd.Timestamp('2018-01-01')]\n",
    "    # Drop rows where there is null or non-positive price or quantity\n",
    "    # First handle weird values (found Quantities with '$')\n",
    "    df['Quantity'] = df['Quantity'].astype(str).apply(lambda s: int(s) if s.isnumeric() else np.nan)\n",
    "    df = df[(df.notna()['Purchase Price Per Unit'] | df.notna()['Quantity'])]\n",
    "    # extract unit price and total price as floats\n",
    "    df['unit price'] = df['Purchase Price Per Unit'].apply(get_unit_price_float)\n",
    "    df['total price'] = df['unit price'] * df['Quantity']\n",
    "    df = df[df['total price'] > 0]\n",
    "    df['yyyy-mm'] = df['Order Date'].apply(lambda d: date.strftime(d, '%Y-%m'))\n",
    "    amzn_df = pd.concat([amzn_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43862427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_metrics(amazon_data_df):\n",
    "    print('%s response Ids' % amazon_data_df['Survey ResponseID'].nunique())\n",
    "    print('%s total rows of data' % len(amazon_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3eca07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5254 response Ids\n",
      "1942117 total rows of data\n"
     ]
    }
   ],
   "source": [
    "print_data_metrics(amzn_df)\n",
    "# amzn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfcdfe",
   "metadata": {},
   "source": [
    "### Handle US states\n",
    "\n",
    "Map U.S. state names to consistent set of 52, or nan\n",
    "- Nan can happen when gift cards are purchased\n",
    "- Nan can happen when items are delivered to a locker\n",
    "\n",
    "Drop purchases not made in the US: Drop if state is neither nan nor in set of US states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70638e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states df contains 52 states\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>abbrev</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALABAMA</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALASKA</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIZONA</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  abbrev code\n",
       "index                        \n",
       "ALABAMA  Alabama    Ala.   AL\n",
       "ALASKA    Alaska  Alaska   AK\n",
       "ARIZONA  Arizona   Ariz.   AZ"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "states_df = pd.read_csv('../data/census/state-abbreviations.csv')\n",
    "states_df['index'] = states_df['state'].apply(lambda s: s.upper())\n",
    "states_df = states_df.set_index('index')\n",
    "state_codes = states_df['code'].to_list()\n",
    "state_names_map = states_df['code'].to_dict()\n",
    "\n",
    "print('states df contains %s states'%len(states_df))\n",
    "\n",
    "def state_code(s):\n",
    "    if not isinstance(s, str): # probably nan (float)\n",
    "        return np.nan\n",
    "    s = re.sub(r'\\.', '', s).upper()\n",
    "    if s in state_codes:\n",
    "        return s\n",
    "    if s in state_names_map:\n",
    "        return state_names_map[s]\n",
    "    return np.nan\n",
    "\n",
    "states_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4923eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a consisent set of state names\n",
    "amzn_df['state'] = amzn_df['Shipping Address State'].apply(state_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6d8cf410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 shippping address states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['RHODE ISLAND', nan, 'SC', 'AL', 'TN', 'MO', 'NY', 'New York',\n",
       "       'TX', 'IL', 'CO', 'CA', 'Mo', 'WI', 'KS', 'PA', 'Pennsylvania',\n",
       "       'MI', 'IA', 'CT', 'Colorado', 'VA', 'FL', 'OH', 'GA', 'WA', 'DE',\n",
       "       'VT', 'MN', 'AZ', 'Az', 'Arizona', 'VIC', 'Texas', 'LOUISIANA',\n",
       "       'LA', 'NC', 'DC', 'ID', 'MT', 'Nevada', 'NV', 'South Carolina',\n",
       "       'NJ', 'MA', 'Ia', 'TEXAS', 'OR', 'WISCONSIN', 'OK', 'PENNSYLVANIA',\n",
       "       'North Carolina', 'ND', 'ILLINOIS', 'ca', 'California', 'KY', 'IN',\n",
       "       'NM', 'New Jersey', 'RI', 'PR', 'MS', 'WV', 'NH', 'AR', 'MD', 'ME',\n",
       "       'SD', 'NE', 'UT', 'Illinois', 'Maryland', 'Massachusetts',\n",
       "       'Washington', 'Ca', 'Wisconsin', 'New york', 'VERMONT',\n",
       "       'CALIFORNIA', 'Ma', 'Mississippi', 'Oklahoma', 'FLORIDA', 'HI',\n",
       "       'PUEBLA', 'Connecticut', 'TENNESSEE', 'Oregon', 'Ontario', 'Ohio',\n",
       "       'New Brunswick', 'AK', 'ARIZONA', 'North carolina', 'Florida',\n",
       "       'COAHUILA DE ZARAGOZA', 'OREGON', 'Va', 'Tennessee', 'Alabama',\n",
       "       'florida', 'MAINE', 'Maine', 'Louisiana', 'Sörmland', 'AP',\n",
       "       'Virginia', 'Georgia', 'Kansas', 'Minnesota', 'NEW MEXICO',\n",
       "       'GEORGIA', 'Kentucky', 'Iowa', 'AE', 'ky', 'GU', 'Indiana', 'WY',\n",
       "       'Ne', 'VI', 'Pa', 'Mn', 'Tx', 'Okinawa', 'MICHIGAN', 'fl',\n",
       "       'Michigan', 'mi', 'wa', 'NEW YORK', 'NEVADA', 'Metro Manila',\n",
       "       'British Columbia', 'Arkansas', 'HAWAII', 'Kenya', 'md', 'Belize',\n",
       "       'ALABAMA', 'OHIO', 'la', 'Fukuoka', 'MASSACHUSETTS', 'MARYLAND',\n",
       "       'NEW JERSEY', 'Montana', 'IDAHO', 'District of Columbia',\n",
       "       'New Hampshire', 'tx', 'pa', 'MONTANA', 'minnesota', 'KARNATAKA',\n",
       "       'oxfordshire', 'Norfolk', 'NAYARIT', 'Fl', 'IOWA', 'Missouri',\n",
       "       'NORTH CAROLINA', 'OKLAHOMA', 'KENTUCKY', 'Nc',\n",
       "       'Selangor Dahrul Ehsan', 'Utah', 'Ok', 'DELAWARE', 'Wyoming',\n",
       "       'Niedersachsen', 'wi', 'Wi', 'CONNECTICUT', 'SOUTH CAROLINA',\n",
       "       'Wien', 'il', 'MISSOURI', 'In', 'Ky', 'WASHINGTON', 'kentucky',\n",
       "       'North Rhine-Westphalia', 'Tokyo', 'INDIANA', 'Ct', 'Oh', 'Ga',\n",
       "       'georgia', 'nj', 'Misamis Oriental', 'Tn', 'SOUTH DAKOTA', 'de',\n",
       "       'Hawaii', 'california', '--Select a State--', 'Puntarenas', 'ny',\n",
       "       'MINNESOTA', 'texas', 'az', 'Al', 'NEBRASKA', 'S Glam', 'VIRGINIA',\n",
       "       'Alberta', 'in', 'La', 'Nebraska', 'va', 'wyoming', 'Bavaria',\n",
       "       'Il', 'ohio', 'West Virginia', 'new jersey', 'oklahoma', 'Kent',\n",
       "       'Wv', 'SAN LUIS POTOSI', 'COLORADO',\n",
       "       'Istrinskiy District, Moscow Region', 'ACT', 'Or', 'alabama',\n",
       "       'Davao del Sur', 'ma', 'illinois', 'BRITISH Columbia', 'Mi',\n",
       "       '72601-8852', 'co', 'Nj', 'Argentina', 'new york', 'oh',\n",
       "       'New Mexico', 'Wa', 'OAXACA', 'NEW HAMPSHIRE',\n",
       "       'Guatemala, Metropolitana', 'North Dakota', 'QLD', 'Ms',\n",
       "       'South Dakota', 'Vermont', 'arizona', 'mn', 'ARKANSAS',\n",
       "       'Iwate Prefecture', 'Ukraine', 'QUINTANA ROO', 'Rhode Island',\n",
       "       'Saskatchewan', 'Idaho', 'Ut', 'XX', 'CIUDAD DE MEXICO', 'Alaska',\n",
       "       'KANSAS', 'Quebec', 'WEST VIRGINIA', 'Queenstown', 'Otago', 'tn',\n",
       "       'Bogota', 'Queensland', 'south carolina', 'ct', 'ga', 'Hong Kong',\n",
       "       'D.C.', 'ar', 'Manitoba', 'Puerto Rico', 'UTAH', 'Ny', 'Dublin',\n",
       "       'NUEVO LEON', 'Swietokrzyskie', 'USPS(9361289678092208744362)',\n",
       "       'USPS(9200192148989923110961)', 'AMZN_US(TBA681177717000)',\n",
       "       'AMZN_US(TBA681525694000)', 'AMZN_US(TBA709834188000)',\n",
       "       'USPS(9405511699000502074243)', 'AMZN_US(TBA744430486000)',\n",
       "       'AMZN_US(TBA743934442000)', 'UPS(1Z9R65E90230305357)',\n",
       "       'AMZN_US(TBA746521516000)', 'USPS(9400111899223591622989)',\n",
       "       'USPS(9374889701090065272069)', 'AMZN_US(TBA775268283000)',\n",
       "       'AMZN_US(TBA805733051000)', 'USPS(9305520111402562591454)',\n",
       "       'AMZN_US(TBA836724144000)', 'FedEx(74893150559678452829)',\n",
       "       'AMZN_US(TBA873071575000)', 'UPSM(9274890207416100940865)',\n",
       "       'ONTRAC(C12340628189808)', 'AMZN_US(TBA876042282000)',\n",
       "       'AMZN_US(TBA903879047000)', 'AMZN_US(TBA906639505000)',\n",
       "       'AMZN_US(TBA920600142000)', 'AMZN_US(TBA920230439000)',\n",
       "       'AMZN_US(TBA924025854000)', 'UPS(1Z3Y13E20225326465)',\n",
       "       'AMZN_US(TBA940976895000)', 'USPS(9400110899533049617621)',\n",
       "       'AMZN_US(TBA968346911000)', 'UPS(1Z306A400285100411)',\n",
       "       'AMZN_US(TBA003546173000)', 'USPS(9374869903502875776234)',\n",
       "       'AMZN_US(TBA010533615000)',\n",
       "       'UPS Mail Innovations(92748963438659543476676155)',\n",
       "       'AMZN_US(TBA037391402000)', 'AMZN_US(TBA037032059000)',\n",
       "       'UPS(1ZE1260F0285095732)', 'UPSMI(92748999983540543537184677)',\n",
       "       'FEDEX(730893626729)', 'USPS(9374889701090126417965)',\n",
       "       'USPS(9400110298370551431546)', 'FEDEX(730713743768)',\n",
       "       'AMZN_US(TBA057888642000)', 'AMZN_US(TBA057863141000)',\n",
       "       'USPS(9400110897877001992213)', 'USPS(9374889701090128717902)',\n",
       "       'AMZN_US(TBA062268622000)', 'AMZN_US(TBA066392536000)',\n",
       "       'AMZN_US(TBA069469989000)', 'AMZL(TBA077884413000)',\n",
       "       'AMZN_US(TBA072424447000)', 'USPS(9200190213413100117669)',\n",
       "       'USPS(9374889701090130183443)', 'AMZN_US(TBA081604656000)',\n",
       "       'UPS(1ZA475Y40228221420)', 'AMZN_US(TBA083799068000)',\n",
       "       'AMZN_US(TBA093140128000)', 'USPS(9400110200864069403157)',\n",
       "       'USPS(00040899563096726435)', 'USPS(9300120111402821752920)',\n",
       "       'AMZN_US(TBA103764818000)', 'AMZN_US(TBA105007362000)',\n",
       "       'AMZN_US(TBA157286122000)', 'USPS(9374889701090137085481)',\n",
       "       'USPS(9400111699000633256560)', 'AMZN_US(TBA137528290000)',\n",
       "       'AMZN_US(TBA140153719000)', 'AMZN_US(TBA148561738000)',\n",
       "       'AMZN_US(TBA183932354000)', 'AMZN_US(TBA184104175000)',\n",
       "       'AMZN_US(TBA191255433000)', 'USPS(9200192148989951470228)',\n",
       "       'USPS(9400111899560154377949)', 'FEDEX(730895469730)',\n",
       "       'USPS(9400111899223148158138)', 'AMZN_US(TBA209402160000)',\n",
       "       'ONTRAC(C12340757923929)', 'AMZN_US(TBA226374238000)',\n",
       "       'AMZN_US(TBA230261988000)', 'AMZN_US(TBA240288946000)',\n",
       "       'AMZN_US(TBA242881284000)', 'AMZN_US(TBA248366913000)',\n",
       "       'AMZN_US(TBA271046373000)', 'AMZN_US(TBA279319497000)',\n",
       "       'USPS(9361289701090171686372)', 'AMZN_US(TBA292586131000)',\n",
       "       'AMZN_US(TBA317722647000)', 'USPS(9305520111403007184736)',\n",
       "       'USPS(9300120111403030405478)', 'USPS(9374889701090181753428)',\n",
       "       'AMZN_US(TBA357653995000)', 'AMZN_US(TBA361101850000)',\n",
       "       'AMZN_US(TBA356643823000)', 'USPS(9274890233818100325102)',\n",
       "       'AMZN_US(TBA369339822000)', 'AMZN_US(TBA371437034000)',\n",
       "       'USPS(9361289701090183906406)', 'AMZN_US(TBA378341362000)',\n",
       "       'AMZN_US(TBA404359914000)', 'AMZN_US(TBA403925267000)',\n",
       "       'AMZN_US(TBA404429868000)', 'AMZN_US(TBA421521647000)',\n",
       "       'AMZN_US(TBA427303101000)', 'AMZN_US(TBA444801646000)',\n",
       "       'USPS(9374889701090194577172)', 'AMZN_US(TBA448421142000)',\n",
       "       'AMZN_US(TBA449093092000)', 'USPS(9300120111403099298233)',\n",
       "       'AMZN_US(TBA455782242000)', 'AMZN_US(TBA459854374000)',\n",
       "       'USPS(9341989701090198258366)', 'AMZN_US(TBA508089224000)',\n",
       "       'AMZN_US(TBA514305924000)', 'UPS(1Z8000V60276308398)',\n",
       "       'AMZN_US(TBA526262514000)', 'AMZN_US(TBA574070617000)',\n",
       "       'AMZN_US(TBA575226724000)', 'AMZN_US(TBA654333583000)',\n",
       "       'AMZN_US(TBA625304428000)', 'AMZN_US(TBA624080505000)',\n",
       "       'AMZN_US(TBA654402946000)', 'USPS(9200190224060823286309)',\n",
       "       'AMZN_US(TBA630068771000)', 'UPS(1Z0915FEPW14379119)',\n",
       "       'USPS(9200190224054036609147)', 'AMZN_US(TBA676729107000)',\n",
       "       'FEDEX(784903992766)', 'USPS(9374889701090239422467)',\n",
       "       'USPS(9200190224058233201722)', 'USPS(9361289701090238857653)',\n",
       "       'AMZN_US(TBA684169456000)', 'AMZN_US(TBA731268445000)',\n",
       "       'AMZN_US(TBA785923953000)', 'AMZN_US(TBA798033270000)',\n",
       "       'AMZN_US(TBA803195767000)', 'USPS(9400111699000838695553)',\n",
       "       'AMZN_US(TBA838540166000)', 'AMZN_US(TBA838959749000)',\n",
       "       'AMZN_US(TBA836153917000)', 'AMZN_US(TBA874702490000)',\n",
       "       'AMZN_US(TBA871351174000)', 'USPS(9374889701090260180008)',\n",
       "       'USPS(9200190224058251447690)', 'AMZN_US(TBA892486616000)',\n",
       "       'AMZN_US(TBA901828211000)', 'AMZN_US(TBA893893560000)',\n",
       "       'AMZN_US(TBA893641960000)', 'AMZN_US(TBA894903259000)',\n",
       "       'AMZN_US(TBA902985910000)', 'AMZN_US(TBA907766064000)',\n",
       "       'AMZN_US(TBA951272479000)', 'AMZN_US(TBA952337711000)',\n",
       "       'UPS(1Z427YA44424304184)', 'AMZN_US(TBA010683229000)',\n",
       "       'Royal Mail', 'AMZN_US(TBA068691029000)',\n",
       "       'AMZN_US(TBA068485939000)', 'AMZN_US(TBA072176294000)',\n",
       "       'AMZN_US(TBA131035902000)', 'SUREPOST(1Z81E22YYN01248448)',\n",
       "       'AMZN_US(TBA131441931000)', 'USPS(9400111699000370326625)',\n",
       "       'UPS Mail Innovations(92748901790731543400809651)',\n",
       "       'AMZN_US(TBA198774978000)', 'AMZN_US(TBA203016098000)',\n",
       "       'USPS(9374889701090283852562)', 'AMZN_US(TBA217194772000)',\n",
       "       'AMZN_US(TBA199323661000)', 'AMZN_US(TBA199244798000)',\n",
       "       'AMZN_US(TBA203138897000)', 'AMZN_US(TBA205747154000)',\n",
       "       'AMZN_US(TBA206588392000)', 'AMZN_US(TBA205492245000)',\n",
       "       'AMZN_US(TBA268198157000)', 'AMZN_US(TBA271066443000)',\n",
       "       'AMZN_US(TBA273616272000)', 'AMZN_US(TBA274543266000)',\n",
       "       'AMZN_US(TBA275261050000)', 'AMZN_US(TBA344157757000)',\n",
       "       'AMZN_US(TBA342423408000)', 'AMZN_US(TBA351967189000)',\n",
       "       'AMZN_US(TBA393923450000)', 'AMZN_US(TBA394255505000)',\n",
       "       'AMZN_US(TBA393998037000)', 'AMZN_US(TBA395931186000)',\n",
       "       'UPS(1Z0929RY0231124905)', 'AMZN_US(TBA415249264000)',\n",
       "       'AMZN_US(TBA412272818000)', 'UPS(1Z552RX80300662713)',\n",
       "       'AMZN_US(TBA410668046000)', 'AMZN_US(TBA413072909000)',\n",
       "       'AMZN_US(TBA410849199000)', 'AMZN_US(TBA411083308000)',\n",
       "       'UPS(1Z2W4E841330035285)', 'AMZN_US(TBA424965148000)',\n",
       "       'UPS(1Z9728Y90310679778)', 'AMZN_US(TBA433811678000)',\n",
       "       'AMZN_US(TBA437095839000)', 'AMZN_US(TBA443035222000)',\n",
       "       'UPSM(9274899993700911385179)', 'AMZN_US(TBA471063914000)',\n",
       "       'AMZN_US(TBA493785711000)', 'AMZN_US(TBA479877978000)',\n",
       "       'AMZN_US(TBA482955426000)', 'UPS(1Z076AW90330378537)',\n",
       "       'AMZN_US(TBA486786260000)', 'UPS(1ZY182671337080144)',\n",
       "       'AMZN_US(TBA486383235000)', 'Japan Post',\n",
       "       'AMZN_US(TBA487129105000)', 'AMZN_US(TBA489379865000)',\n",
       "       'AMZN_US(TBA490249506000)', 'AMZN_US(TBA493136824000)',\n",
       "       'AMZN_US(TBA492334970000)', 'AMZN_US(TBA514600009000)',\n",
       "       'AMZN_US(TBA594992727000)', 'UPS(1ZY182671339615107)',\n",
       "       'UPS(1ZY182670239919612)', 'AMZN_US(TBA619556435000)',\n",
       "       'EUB(LW932225509CN)', 'AMZN_US(TBA620294373000)',\n",
       "       'EUB(LW934014989CN)', 'USPS(9361289701090314398650)',\n",
       "       'AMZN_US(TBA653155334000)', 'AMZN_US(TBA687246718000)',\n",
       "       'AMZN_US(TBA686445717000)', 'AMZN_US(TBA693565842000)',\n",
       "       'AMZN_US(TBA749488214000)', 'USPS(9200192148989972355474)',\n",
       "       'AMZN_US(TBA803571992000)', 'AMZN_US(TBA813802123000)',\n",
       "       'USPS(9200190224058160410679)', 'AMZN_US(TBA814865310000)',\n",
       "       'AMZN_US(TBA830386880000)', 'AMZN_US(TBA844448446000)',\n",
       "       'AMZN_US(TBA859842611000)', 'AMZN_US(TBA860781574000)',\n",
       "       'AMZN_US(TBA874490632000)', 'AMZN_US(TBA877005255000)',\n",
       "       'USPS(9400110298192004710288)', 'USPS(9200190224054082316815)',\n",
       "       'UPS(1Z975W5A0215322136)', 'AMZN_US(TBA891218863000)',\n",
       "       'AMZN_US(TBA891619798000)', 'AMZN_US(TBA899654208000)',\n",
       "       'AMZN_US(TBA912717950000)',\n",
       "       'DHL Global Mail(9374869903504139917988)',\n",
       "       'AMZN_US(TBA947681637000)', 'AMZN_US(TBA948690845000)',\n",
       "       'AMZN_US(TBA948196826000)', 'AMZN_US(TBA947547989000)',\n",
       "       'AMZN_US(TBA953513296000)', 'AMZN_US(TBA958142160000)',\n",
       "       'AMZN_US(TBA963094018000)', 'AMZN_US(TBA959238672000)',\n",
       "       'AMZN_US(TBA971278516000)', 'UPS(1Z5Y68W50329134180)',\n",
       "       'AMZN_US(TBA982613177000)', 'AMZN_US(TBA983140185000)',\n",
       "       'AMZN_US(TBA986948925000)', 'AMZN_US(TBA989463220000)',\n",
       "       'AMZN_US(TBA995333823000)', 'AMZN_US(TBA033009637000)',\n",
       "       'AMZN_US(TBA036035784000)', 'USPS(9200190224058200827399)',\n",
       "       'AMZN_US(TBA043212869000)', 'UPS(1Z5Y68W50329842870)',\n",
       "       'AMZN_US(TBA060673643000)', 'AMZN_US(TBA103615028000)',\n",
       "       'AMZN_US(TBA122053709000)', 'AMZN_US(TBA121120605000)',\n",
       "       'AMZN_US(TBA127892260000)', 'AMZN_US(TBA130592053000)',\n",
       "       'AMZN_US(TBA169756504000)', 'AMZN_US(TBA214187612000)',\n",
       "       'AMZN_US(TBA213497110000)', 'AMZN_US(TBA241814408000)',\n",
       "       'AMZN_US(TBA247505398000)', 'AMZN_US(TBA250037272000)',\n",
       "       'UPS(1Z9YF2121302177359)', 'USPS(9374889701090368352369)',\n",
       "       'AMZN_US(TBA346027766000)', 'USPS(9374889701090372464126)',\n",
       "       'USPS(9374889701090373289759)', 'AMZN_US(TBA332792092000)',\n",
       "       'OSM BPM Mail(9241990226079704034145)', 'AMZN_US(TBA356644977000)',\n",
       "       'AMZN_US(TBA357893652000)', 'UPS(1Z5Y68W50333867210)',\n",
       "       'AMZN_US(TBA448275470000)', 'AMZN_US(TBA481063621000)',\n",
       "       'AMZN_US(TBA489719558000)', 'USPS(9374889701090399493888)',\n",
       "       'AMZN_US(TBA478900117000)', 'AMZN_US(TBA501238150000)',\n",
       "       'AMZN_US(TBA548503484000)', 'USPS(9200190224060792526901)',\n",
       "       'AMZN_US(TBA550408832000)', 'AMZN_US(TBA549587372000)',\n",
       "       'AMZN_US(TBA637760892000)', 'AMZN_US(TBA637807520000)',\n",
       "       'AMZN_US(TBA636401708000)', 'AMZN_US(TBA686241599000)',\n",
       "       'AMZN_US(TBA687877758000)', 'China Post(LS225189489CN)',\n",
       "       'AMZN_US(TBA687957647000)', 'AMZN_US(TBA694946073000)',\n",
       "       'AMZN_US(TBA690035871000)', 'AMZN_US(TBA692610544000)',\n",
       "       'USPS(9374889701090423372455)', 'AMZN_US(TBA689103347000)',\n",
       "       'AMZN_US(TBA688986315000)', 'AMZN_US(TBA693488006000)',\n",
       "       'AMZN_US(TBA703278366000)', 'USPS(9361289701090425029672)',\n",
       "       'AMZN_US(TBA774479172000)', 'USPS(9361289701090429944735)',\n",
       "       'UPS(1Z129F380262772186)', 'AMZN_US(TBA844614847000)',\n",
       "       'USPS(9374889701090436786195)', 'AMZN_US(TBA864790689000)',\n",
       "       'AMZN_US(TBA872260500000)', 'AMZN_US(TBA879154361000)',\n",
       "       'USPS(9361289701090437749308)', 'USPS(9300120111404315488353)',\n",
       "       'AMZN_US(TBA894845375000)', 'AMZN_US(TBA902282837000)',\n",
       "       'AMZN_US(TBA942815697000)', 'USPS(9374889701090459329102)',\n",
       "       'USPS(9374889701090462659753)', 'USPS(9361289701090461760010)',\n",
       "       'AMZN_US(TBA150881952000)', 'USPS(9400111899223332531822)',\n",
       "       'UPS(1Z8Y82X01340994154)', 'USPS(9374889701090464036293)',\n",
       "       'AMZN_US(TBA208656793000)', 'USPS(LS301497651CN)',\n",
       "       'AMZN_US(TBA004001186101)', 'AMZN_US(TBA004700801401)',\n",
       "       'USPS(9400109205568610731537)', 'AMZN_US(TBA006151018801)',\n",
       "       'USPS(9300120111404508084607)', 'USPS(9361289701090479413199)',\n",
       "       'UPS(1Z9YF1801316709097)', 'UPS(1Z6A390F0304198979)',\n",
       "       'USPS(9374889701090483032153)', 'USPS(9374889701090481289023)',\n",
       "       'FedEx(392825145091)', 'USPS(9374889701090488433528)',\n",
       "       'UPS(1Z9X66Y31352337152)', 'AMZN_US(TBA029357560801)',\n",
       "       'USPS(9361289701090493865417)', 'AMZN_US(TBA025274229601)',\n",
       "       'USPS(9400111899281881926605)', 'UPS(1Z9YF1891303497717)',\n",
       "       'UPS(1Z15998R0317190560)', 'AMZN_US(TBA036761141001)',\n",
       "       'USPS(9300120111404792467278)', 'AMZN_US(TBA040494227301)',\n",
       "       'AMZN_US(TBA040425385901)', 'UPS(1Z6A390F0305155610)',\n",
       "       'USPS(9361289701090506803542)', 'AMZN_US(TBA042754405201)',\n",
       "       'AMZN_US(TBA048869243901)', 'AMZN_US(TBA046900754401)',\n",
       "       'AMZN_US(TBA047003598901)', 'AMZN_US(TBA047539470101)',\n",
       "       'AMZN_US(TBA047397177101)', 'AMZN_US(TBA049654807601)',\n",
       "       'USPS(9305520111499570375787)', 'AMZN_US(TBA051188470701)',\n",
       "       'AMZN_US(TBA050967187101)', 'AMZN_US(TBA055193991901)',\n",
       "       'AMZN_US(TBA056700526901)', 'AMZN_US(TBA060878893201)',\n",
       "       'AMZN_US(TBA066703245001)', 'FedEx(394207454518)',\n",
       "       'UPS(1Z9X26970310004807)', 'USPS(9405510298370122363651)',\n",
       "       'AMZN_US(TBA072183268801)', 'AMZN_US(TBA071691520801)',\n",
       "       'AMZN_US(TBA072093653701)', 'USPS(9374889701090535310215)',\n",
       "       'AMZN_US(TBA077775691801)', 'FedEx(903208534149)',\n",
       "       'UPS(1Z6A390F0306442165)', 'AMZN_US(TBA079406043001)',\n",
       "       'AMZN_US(TBA079733507601)', 'AMZN_US(TBA080599805701)',\n",
       "       'AMZN_US(TBA083720446801)', 'USPS(9374889701090542394895)',\n",
       "       'AMZN_US(TBA084098201501)', 'AMZN_US(TBA083702459301)',\n",
       "       'AMZN_US(TBA086465706101)', 'AMZN_US(TBA086543390401)',\n",
       "       'AMZN_US(TBA086660823801)', 'UPS(1Z1480AE0380261162)',\n",
       "       'AMZN_US(TBA085293368301)', 'UPS(1Z1480AE0380317647)',\n",
       "       'AMZN_US(TBA084772312001)', 'AMZN_US(TBA085836370001)',\n",
       "       'AMZN_US(TBA087005072201)', 'USPS(9374889701090548052102)',\n",
       "       'AMZN_US(TBA089072160501)', 'AMZN_US(TBA089153895101)',\n",
       "       'AMZN_US(TBA089669511601)', 'AMZN_US(TBA089650464701)',\n",
       "       'AMZN_US(TBA089782605401)', 'AMZN_US(TBA090557303201)',\n",
       "       'USPS(9400111899563207215533)', 'AMZN_US(TBA090816293801)',\n",
       "       'AMZN_US(TBA091013887701)', 'AMZN_US(TBA092548962901)',\n",
       "       'AMZN_US(TBA100090152001)', 'AMZN_US(TBA105068839101)',\n",
       "       '4PX(302781137668)', 'USPS(9400110298192008940919)',\n",
       "       'AMZN_US(TBA111091323401)', 'AMZN_US(TBA113765470601)',\n",
       "       'AMZN_US(TBA116003373701)', 'USPS(9374889701090584846741)',\n",
       "       'AMZN_US(TBA125223053701)', 'AMZN_US(TBA126398841501)',\n",
       "       'UPS(1Z6A390F0307838236)', 'AMZN_US(TBA129388416401)',\n",
       "       'USPS(9374889701090589027435)', 'USPS(9374889701090589226876)',\n",
       "       'USPS(9374889701090589246003)', 'AMZN_US(TBA132155339101)',\n",
       "       'USPS(9374889701090592769360)', 'USPS(9374889701090592349807)',\n",
       "       'USPS(9374889701090591642763)', 'USPS(9400110298192009246416)',\n",
       "       'USPS(9374889701090591799085)', 'UPS(1Z69VR561372467178)',\n",
       "       'USPS(9374889701090594651823)', 'UPS(1Z593Y0R0312416163)',\n",
       "       'AMZN_US(TBA145688704801)', 'AMZN_US(TBA145540727101)',\n",
       "       'USPS(9374889701090605090351)', 'AMZN_US(TBA000692045204)',\n",
       "       'AMZN_US(TBA147526077501)', 'AMZN_US(TBA000524310004)',\n",
       "       'AMZN_US(TBA003132328104)', 'USPS(9361289701090609529103)',\n",
       "       'FedEx(396946093833)', 'AMZN_US(TBA015010230904)',\n",
       "       'AMZN_US(TBA015581812604)', 'AMZN_US(TBA017345009204)',\n",
       "       'AMZN_US(TBA018351366504)', 'AMZN_US(TBA028638960104)',\n",
       "       'USPS(9405511202555702823996)', 'AMZN_US(TBA029468238304)',\n",
       "       'AMZN_US(TBA029696500904)', 'AMZN_US(TBA030751639804)',\n",
       "       'AMZN_US(TBA035539068004)', 'AMZN_US(TBA040471330604)',\n",
       "       'DHL Global Mail(420890159361269903505714542940)',\n",
       "       'AMZN_US(TBA038587859704)', 'AMZN_US(TBA041906295104)',\n",
       "       'AMZN_US(TBA043377022004)', 'AMZN_US(TBA044160327404)',\n",
       "       'AMZN_US(TBA044450021504)', 'USPS(9374889701090646225910)',\n",
       "       'AMZN_US(TBA066754205504)', 'AMZN_US(TBA067339747304)',\n",
       "       'AMZN_US(TBA066029544504)', 'AMZN_US(TBA070142657204)',\n",
       "       'AMZN_US(TBA069548946904)', 'AMZN_US(TBA070110653004)',\n",
       "       'AMZN_US(TBA071053531404)', 'AMZN_US(TBA070658997704)',\n",
       "       'Amazon(TBA071244976404)', 'UPS(1Z81WV730209855584)',\n",
       "       'AMZN_US(TBA071017664404)', 'AMZN_US(TBA072113924404)',\n",
       "       'USPS(9374889701090654584146)', 'AMZN_US(TBA092544601804)',\n",
       "       'AMZN_US(TBA093376155404)', 'AMZN_US(TBA093902303604)',\n",
       "       'AMZN_US(TBA094429025504)', 'AMZN_US(TBA113130056904)',\n",
       "       'AMZN_US(TBA116696148004)', 'USPS(9374889701090665921954)',\n",
       "       'AMZN_US(TBA119502153104)', 'UPS(1Z6A390F0310967573)',\n",
       "       'AMZN_US(TBA293359968000)', 'AMZN_US(TBA133884045604)',\n",
       "       'AMZN_US(TBA135218514604)', 'AMZN_US(TBA138334877704)',\n",
       "       'AMZN_US(TBA143484611204)', 'USPS(9374889701090675476208)',\n",
       "       'AMZN_US(TBA143177920404)', 'AMZN_US(TBA148077460904)',\n",
       "       'AMZN_US(TBA148849284004)', 'AMZN_US(TBA151651824204)',\n",
       "       'AMZN_US(TBA152068507004)', 'AMZN_US(TBA159036852304)',\n",
       "       'AMZN_US(TBA162569476304)', 'AMZN_US(TBA162698817204)',\n",
       "       'AMZN_US(TBA163221560904)', 'USPS(9374889701090682897980)',\n",
       "       'AMZN_US(TBA167442891204)', 'AMZN_US(TBA167240528904)',\n",
       "       'AMZN_US(TBA169378095004)', 'AMZN_US(TBA169252733804)',\n",
       "       'AMZN_US(TBA173620131004)', 'AMZN_US(TBA173843026204)',\n",
       "       'AMZN_US(TBA174771282404)', 'AMZN_US(TBA174695161104)',\n",
       "       'AMZN_US(TBA175364827004)', 'AMZN_US(TBA177943890704)',\n",
       "       'AMZN_US(TBA175751600104)', 'AMZN_US(TBA186135853704)',\n",
       "       'AMZN_US(TBA307903734000)', 'AMZN_US(TBA190040706504)',\n",
       "       'AMZN_US(TBA002918623804)', 'AMZN_US(TBA002387195304)',\n",
       "       'AMZN_US(TBA001571427404)', 'AMZN_US(TBA008564544104)',\n",
       "       'AMZN_US(TBA007051891204)', 'AMZN_US(TBA007099140204)',\n",
       "       'UPS(1Z6A390F0312665538)', 'AMZN_US(TBA016352822204)',\n",
       "       'AMZN_US(TBA317059549000)', 'DHL(420890159374869903506579219226)',\n",
       "       'UPS(1Z813R301315802704)', 'AMZN_US(TBA022380592304)',\n",
       "       'USPS(9405511108296502696476)', 'AMZN_US(TBA022059533404)',\n",
       "       'AMZN_US(TBA024483246504)', 'AMZN_US(TBA024758015804)',\n",
       "       'AMZN_US(TBA024583717004)', 'AMZN_US(TBA033854603104)',\n",
       "       'AMZN_US(TBA027400037204)', 'AMZN_US(TBA028597269104)',\n",
       "       'AMZN_US(TBA320364305000)', 'AMZN_US(TBA029276675404)',\n",
       "       'AMZN_US(TBA073275445404)', 'AMZN_US(TBA074528516004)',\n",
       "       'AMZN_US(TBA104805001204)', 'AMZN_US(TBA104938336804)',\n",
       "       'AMZN_US(TBA104969131104)', 'AMZN_US(TBA106180684204)',\n",
       "       'AMZN_US(TBA108139064004)', 'AMZN_US(TBA364242644000)',\n",
       "       'AMZN_US(TBA164889458504)', 'AMZN_US(TBA409211406000)',\n",
       "       'AMZN_US(TBA043054368404)', 'AMZN_US(TBA043527956804)',\n",
       "       'AMZN_US(TBA044328668404)', 'AMZN_US(TBA044438320304)',\n",
       "       'USPS(9374889701006743483641)', 'AMZN_US(TBA060629386304)',\n",
       "       'AMZN_US(TBA063020768904)', 'AMZN_US(TBA078948672604)',\n",
       "       'USPS(9374889701007777117380)', 'AMZN_US(TBA103348320004)',\n",
       "       'AMZN_US(TBA105350579504)', 'AMZN_US(TBA110573918804)',\n",
       "       'AMZN_US(TBA144061479304)', 'AMZN_US(TBA146091380304)',\n",
       "       'USPS(9374889701009200082036)', 'AMZN_US(TBA179779212004)',\n",
       "       'AMZN_US(TBA182502864104)', 'AMZN_US(TBA199220151504)',\n",
       "       'AMZN_US(TBA029565427704)', 'AMZN_US(TBA050665026904)',\n",
       "       'USPS(9374889701010608089831)', 'AMZN_US(TBA127094279804)',\n",
       "       'AMZN_US(TBA129611905004)', 'AMZN_US(TBA133380963204)',\n",
       "       'AMZN_US(TBA133446596504)', 'AMZN_US(TBA039295092104)',\n",
       "       'AMZN_US(TBA039767447804)', 'AMZN_US(TBA055755756304)',\n",
       "       'AMZN_US(TBA049317790304)', 'UPS(1Z82V7481340298048)',\n",
       "       'AMZN_US(TBA303310676561)', 'UPS(1Z9A403R0325831732)',\n",
       "       'AMZN_US(TBA303503759702)', 'AMZN_US(TBA777856753000)',\n",
       "       'AMZN_US(TBA779076924000)', 'AMZN_US(TBA303669955025)',\n",
       "       'UPS(1Z83797X0285719924)', 'AMZN_US(TBA304195520918)',\n",
       "       'AMZN_US(TBA304245182789)', 'AMZN_US(TBA304388656735)',\n",
       "       'AMZN_US(TBA304289237047)', 'AMZN_US(TBA304302031854)',\n",
       "       'AMZN_US(TBA304343019656)', 'AMZN_US(TBA304328384372)',\n",
       "       'UPS(1Z4E3W290315382658)', 'AMZN_US(TBA304641260603)',\n",
       "       'AMZN_US(TBA304730455450)', 'AMZN_US(TBA304713399048)',\n",
       "       'AMZN_US(TBA304723766586)', 'AMZN_US(TBA304834242476)',\n",
       "       'AMZN_US(TBA304889394828)', 'AMZN_US(TBA304966534152)',\n",
       "       'AMZN_US(TBA304960015006)', 'Yanwen(UG878348002YP)',\n",
       "       'AMZN_US(TBA305009967564)', 'AMZN_US(TBA305021479645)',\n",
       "       'USPS(9374889720118171897114)', 'AMZN_US(TBA305388485956)',\n",
       "       'SF Express(SF6043545498225)', 'Western Australia', 'al', 'nc',\n",
       "       'Irbid', 'Co', 'Edo. Nva. Esparta', 'aragua', 'AA', 'Delaware',\n",
       "       'Victoria', 'WYOMING', 'Lincolnshire', 'N.J.', 'ALASKA', 'sc',\n",
       "       'nh', 'DKI', 'Tecamac', 'Alajuela', ' '], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snames = amzn_df['Shipping Address State'].unique()\n",
    "print('%s shippping address states'%len(snames))\n",
    "snames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e43bcec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98928 purchases without a US state\n",
      "Shipping Address State\n",
      "nan                         96684\n",
      "AE                            297\n",
      "AP                            248\n",
      "                              190\n",
      "AA                            181\n",
      "                            ...  \n",
      "AMZN_US(TBA304302031854)        1\n",
      "AMZN_US(TBA304289237047)        1\n",
      "AMZN_US(TBA304245182789)        1\n",
      "AMZN_US(TBA303503759702)        1\n",
      "oxfordshire                     1\n",
      "Name: Order Date, Length: 678, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no_state_df = amzn_df[amzn_df['state'].isna()].copy()\n",
    "print('%s purchases without a US state' % len(no_state_df))\n",
    "no_state_df['Shipping Address State'] = no_state_df['Shipping Address State'].astype(str)\n",
    "print(no_state_df.groupby(\n",
    "    'Shipping Address State'\n",
    ").count()['Order Date'].sort_values(ascending=False))\n",
    "# no_state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "339b9f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 shipping codes\n",
      "2 unique Response Ids with shipping codes\n"
     ]
    }
   ],
   "source": [
    "# There are a lot of shipping codes\n",
    "# I think someone updated the columns of their data and accidentally replaced Shipping Address State with this shipping info\n",
    "# Only 2 respondents. So we don't handle these.\n",
    "shipping_codes = ['USPS(9361289678092208744362)', 'USPS(9200192148989923110961)', 'AMZN_US(TBA681177717000)', 'AMZN_US(TBA681525694000)', 'AMZN_US(TBA709834188000)', 'USPS(9405511699000502074243)', 'AMZN_US(TBA744430486000)', 'AMZN_US(TBA743934442000)', 'UPS(1Z9R65E90230305357)', 'AMZN_US(TBA746521516000)', 'USPS(9400111899223591622989)', 'USPS(9374889701090065272069)', 'AMZN_US(TBA775268283000)', 'AMZN_US(TBA805733051000)', 'USPS(9305520111402562591454)', 'AMZN_US(TBA836724144000)', 'FedEx(74893150559678452829)', 'AMZN_US(TBA873071575000)', 'UPSM(9274890207416100940865)', 'ONTRAC(C12340628189808)', 'AMZN_US(TBA876042282000)', 'AMZN_US(TBA903879047000)', 'AMZN_US(TBA906639505000)', 'AMZN_US(TBA920600142000)', 'AMZN_US(TBA920230439000)', 'AMZN_US(TBA924025854000)', 'UPS(1Z3Y13E20225326465)', 'AMZN_US(TBA940976895000)', 'USPS(9400110899533049617621)', 'AMZN_US(TBA968346911000)', 'UPS(1Z306A400285100411)', 'AMZN_US(TBA003546173000)', 'USPS(9374869903502875776234)', 'AMZN_US(TBA010533615000)', 'UPS Mail Innovations(92748963438659543476676155)', 'AMZN_US(TBA037391402000)', 'AMZN_US(TBA037032059000)', 'UPS(1ZE1260F0285095732)', 'UPSMI(92748999983540543537184677)', 'FEDEX(730893626729)', 'USPS(9374889701090126417965)', 'USPS(9400110298370551431546)', 'FEDEX(730713743768)', 'AMZN_US(TBA057888642000)', 'AMZN_US(TBA057863141000)', 'USPS(9400110897877001992213)', 'USPS(9374889701090128717902)', 'AMZN_US(TBA062268622000)', 'AMZN_US(TBA066392536000)', 'AMZN_US(TBA069469989000)', 'AMZL(TBA077884413000)', 'AMZN_US(TBA072424447000)', 'USPS(9200190213413100117669)', 'USPS(9374889701090130183443)', 'AMZN_US(TBA081604656000)', 'UPS(1ZA475Y40228221420)', 'AMZN_US(TBA083799068000)', 'AMZN_US(TBA093140128000)', 'USPS(9400110200864069403157)', 'USPS(00040899563096726435)', 'USPS(9300120111402821752920)', 'AMZN_US(TBA103764818000)', 'AMZN_US(TBA105007362000)', 'AMZN_US(TBA157286122000)', 'USPS(9374889701090137085481)', 'USPS(9400111699000633256560)', 'AMZN_US(TBA137528290000)', 'AMZN_US(TBA140153719000)', 'AMZN_US(TBA148561738000)', 'AMZN_US(TBA183932354000)', 'AMZN_US(TBA184104175000)', 'AMZN_US(TBA191255433000)', 'USPS(9200192148989951470228)', 'USPS(9400111899560154377949)', 'FEDEX(730895469730)', 'USPS(9400111899223148158138)', 'AMZN_US(TBA209402160000)', 'ONTRAC(C12340757923929)', 'AMZN_US(TBA226374238000)', 'AMZN_US(TBA230261988000)', 'AMZN_US(TBA240288946000)', 'AMZN_US(TBA242881284000)', 'AMZN_US(TBA248366913000)', 'AMZN_US(TBA271046373000)', 'AMZN_US(TBA279319497000)', 'USPS(9361289701090171686372)', 'AMZN_US(TBA292586131000)', 'AMZN_US(TBA317722647000)', 'USPS(9305520111403007184736)', 'USPS(9300120111403030405478)', 'USPS(9374889701090181753428)', 'AMZN_US(TBA357653995000)', 'AMZN_US(TBA361101850000)', 'AMZN_US(TBA356643823000)', 'USPS(9274890233818100325102)', 'AMZN_US(TBA369339822000)', 'AMZN_US(TBA371437034000)', 'USPS(9361289701090183906406)', 'AMZN_US(TBA378341362000)', 'AMZN_US(TBA404359914000)', 'AMZN_US(TBA403925267000)', 'AMZN_US(TBA404429868000)', 'AMZN_US(TBA421521647000)', 'AMZN_US(TBA427303101000)', 'AMZN_US(TBA444801646000)', 'USPS(9374889701090194577172)', 'AMZN_US(TBA448421142000)', 'AMZN_US(TBA449093092000)', 'USPS(9300120111403099298233)', 'AMZN_US(TBA455782242000)', 'AMZN_US(TBA459854374000)', 'USPS(9341989701090198258366)', 'AMZN_US(TBA508089224000)', 'AMZN_US(TBA514305924000)', 'UPS(1Z8000V60276308398)', 'AMZN_US(TBA526262514000)', 'AMZN_US(TBA574070617000)', 'AMZN_US(TBA575226724000)', 'AMZN_US(TBA654333583000)', 'AMZN_US(TBA625304428000)', 'AMZN_US(TBA624080505000)', 'AMZN_US(TBA654402946000)', 'USPS(9200190224060823286309)', 'AMZN_US(TBA630068771000)', 'UPS(1Z0915FEPW14379119)', 'USPS(9200190224054036609147)', 'AMZN_US(TBA676729107000)', 'FEDEX(784903992766)', 'USPS(9374889701090239422467)', 'USPS(9200190224058233201722)', 'USPS(9361289701090238857653)', 'AMZN_US(TBA684169456000)', 'AMZN_US(TBA731268445000)', 'AMZN_US(TBA785923953000)', 'AMZN_US(TBA798033270000)', 'AMZN_US(TBA803195767000)', 'USPS(9400111699000838695553)', 'AMZN_US(TBA838540166000)', 'AMZN_US(TBA838959749000)', 'AMZN_US(TBA836153917000)', 'AMZN_US(TBA874702490000)', 'AMZN_US(TBA871351174000)', 'USPS(9374889701090260180008)', 'USPS(9200190224058251447690)', 'AMZN_US(TBA892486616000)', 'AMZN_US(TBA901828211000)', 'AMZN_US(TBA893893560000)', 'AMZN_US(TBA893641960000)', 'AMZN_US(TBA894903259000)', 'AMZN_US(TBA902985910000)', 'AMZN_US(TBA907766064000)', 'AMZN_US(TBA951272479000)', 'AMZN_US(TBA952337711000)', 'UPS(1Z427YA44424304184)', 'AMZN_US(TBA010683229000)', 'Royal Mail', 'AMZN_US(TBA068691029000)', 'AMZN_US(TBA068485939000)', 'AMZN_US(TBA072176294000)', 'AMZN_US(TBA131035902000)', 'SUREPOST(1Z81E22YYN01248448)', 'AMZN_US(TBA131441931000)', 'USPS(9400111699000370326625)', 'UPS Mail Innovations(92748901790731543400809651)', 'AMZN_US(TBA198774978000)', 'AMZN_US(TBA203016098000)', 'USPS(9374889701090283852562)', 'AMZN_US(TBA217194772000)', 'AMZN_US(TBA199323661000)', 'AMZN_US(TBA199244798000)', 'AMZN_US(TBA203138897000)', 'AMZN_US(TBA205747154000)', 'AMZN_US(TBA206588392000)', 'AMZN_US(TBA205492245000)', 'AMZN_US(TBA268198157000)', 'AMZN_US(TBA271066443000)', 'AMZN_US(TBA273616272000)', 'AMZN_US(TBA274543266000)', 'AMZN_US(TBA275261050000)', 'AMZN_US(TBA344157757000)', 'AMZN_US(TBA342423408000)', 'AMZN_US(TBA351967189000)', 'AMZN_US(TBA393923450000)', 'AMZN_US(TBA394255505000)', 'AMZN_US(TBA393998037000)', 'AMZN_US(TBA395931186000)', 'UPS(1Z0929RY0231124905)', 'AMZN_US(TBA415249264000)', 'AMZN_US(TBA412272818000)', 'UPS(1Z552RX80300662713)', 'AMZN_US(TBA410668046000)', 'AMZN_US(TBA413072909000)', 'AMZN_US(TBA410849199000)', 'AMZN_US(TBA411083308000)', 'UPS(1Z2W4E841330035285)', 'AMZN_US(TBA424965148000)', 'UPS(1Z9728Y90310679778)', 'AMZN_US(TBA433811678000)', 'AMZN_US(TBA437095839000)', 'AMZN_US(TBA443035222000)', 'UPSM(9274899993700911385179)', 'AMZN_US(TBA471063914000)', 'AMZN_US(TBA493785711000)', 'AMZN_US(TBA479877978000)', 'AMZN_US(TBA482955426000)', 'UPS(1Z076AW90330378537)', 'AMZN_US(TBA486786260000)', 'UPS(1ZY182671337080144)', 'AMZN_US(TBA486383235000)', 'Japan Post', 'AMZN_US(TBA487129105000)', 'AMZN_US(TBA489379865000)', 'AMZN_US(TBA490249506000)', 'AMZN_US(TBA493136824000)', 'AMZN_US(TBA492334970000)', 'AMZN_US(TBA514600009000)', 'AMZN_US(TBA594992727000)', 'UPS(1ZY182671339615107)', 'UPS(1ZY182670239919612)', 'AMZN_US(TBA619556435000)', 'EUB(LW932225509CN)', 'AMZN_US(TBA620294373000)', 'EUB(LW934014989CN)', 'USPS(9361289701090314398650)', 'AMZN_US(TBA653155334000)', 'AMZN_US(TBA687246718000)', 'AMZN_US(TBA686445717000)', 'AMZN_US(TBA693565842000)', 'AMZN_US(TBA749488214000)', 'USPS(9200192148989972355474)', 'AMZN_US(TBA803571992000)', 'AMZN_US(TBA813802123000)', 'USPS(9200190224058160410679)', 'AMZN_US(TBA814865310000)', 'AMZN_US(TBA830386880000)', 'AMZN_US(TBA844448446000)', 'AMZN_US(TBA859842611000)', 'AMZN_US(TBA860781574000)', 'AMZN_US(TBA874490632000)', 'AMZN_US(TBA877005255000)', 'USPS(9400110298192004710288)', 'USPS(9200190224054082316815)', 'UPS(1Z975W5A0215322136)', 'AMZN_US(TBA891218863000)', 'AMZN_US(TBA891619798000)', 'AMZN_US(TBA899654208000)', 'AMZN_US(TBA912717950000)', 'DHL Global Mail(9374869903504139917988)', 'AMZN_US(TBA947681637000)', 'AMZN_US(TBA948690845000)', 'AMZN_US(TBA948196826000)', 'AMZN_US(TBA947547989000)', 'AMZN_US(TBA953513296000)', 'AMZN_US(TBA958142160000)', 'AMZN_US(TBA963094018000)', 'AMZN_US(TBA959238672000)', 'AMZN_US(TBA971278516000)', 'UPS(1Z5Y68W50329134180)', 'AMZN_US(TBA982613177000)', 'AMZN_US(TBA983140185000)', 'AMZN_US(TBA986948925000)', 'AMZN_US(TBA989463220000)', 'AMZN_US(TBA995333823000)', 'AMZN_US(TBA033009637000)', 'AMZN_US(TBA036035784000)', 'USPS(9200190224058200827399)', 'AMZN_US(TBA043212869000)', 'UPS(1Z5Y68W50329842870)', 'AMZN_US(TBA060673643000)', 'AMZN_US(TBA103615028000)', 'AMZN_US(TBA122053709000)', 'AMZN_US(TBA121120605000)', 'AMZN_US(TBA127892260000)', 'AMZN_US(TBA130592053000)', 'AMZN_US(TBA169756504000)', 'AMZN_US(TBA214187612000)', 'AMZN_US(TBA213497110000)', 'AMZN_US(TBA241814408000)', 'AMZN_US(TBA247505398000)', 'AMZN_US(TBA250037272000)', 'UPS(1Z9YF2121302177359)', 'USPS(9374889701090368352369)', 'AMZN_US(TBA346027766000)', 'USPS(9374889701090372464126)', 'USPS(9374889701090373289759)', 'AMZN_US(TBA332792092000)', 'OSM BPM Mail(9241990226079704034145)', 'AMZN_US(TBA356644977000)', 'AMZN_US(TBA357893652000)', 'UPS(1Z5Y68W50333867210)', 'AMZN_US(TBA448275470000)', 'AMZN_US(TBA481063621000)', 'AMZN_US(TBA489719558000)', 'USPS(9374889701090399493888)', 'AMZN_US(TBA478900117000)', 'AMZN_US(TBA501238150000)', 'AMZN_US(TBA548503484000)', 'USPS(9200190224060792526901)', 'AMZN_US(TBA550408832000)', 'AMZN_US(TBA549587372000)', 'AMZN_US(TBA637760892000)', 'AMZN_US(TBA637807520000)', 'AMZN_US(TBA636401708000)', 'AMZN_US(TBA686241599000)', 'AMZN_US(TBA687877758000)', 'China Post(LS225189489CN)', 'AMZN_US(TBA687957647000)', 'AMZN_US(TBA694946073000)', 'AMZN_US(TBA690035871000)', 'AMZN_US(TBA692610544000)', 'USPS(9374889701090423372455)', 'AMZN_US(TBA689103347000)', 'AMZN_US(TBA688986315000)', 'AMZN_US(TBA693488006000)', 'AMZN_US(TBA703278366000)', 'USPS(9361289701090425029672)', 'AMZN_US(TBA774479172000)', 'USPS(9361289701090429944735)', 'UPS(1Z129F380262772186)', 'AMZN_US(TBA844614847000)', 'USPS(9374889701090436786195)', 'AMZN_US(TBA864790689000)', 'AMZN_US(TBA872260500000)', 'AMZN_US(TBA879154361000)', 'USPS(9361289701090437749308)', 'USPS(9300120111404315488353)', 'AMZN_US(TBA894845375000)', 'AMZN_US(TBA902282837000)', 'AMZN_US(TBA942815697000)', 'USPS(9374889701090459329102)', 'USPS(9374889701090462659753)', 'USPS(9361289701090461760010)', 'AMZN_US(TBA150881952000)', 'USPS(9400111899223332531822)', 'UPS(1Z8Y82X01340994154)', 'USPS(9374889701090464036293)', 'AMZN_US(TBA208656793000)', 'USPS(LS301497651CN)', 'AMZN_US(TBA004001186101)', 'AMZN_US(TBA004700801401)', 'USPS(9400109205568610731537)', 'AMZN_US(TBA006151018801)', 'USPS(9300120111404508084607)', 'USPS(9361289701090479413199)', 'UPS(1Z9YF1801316709097)', 'UPS(1Z6A390F0304198979)', 'USPS(9374889701090483032153)', 'USPS(9374889701090481289023)', 'FedEx(392825145091)', 'USPS(9374889701090488433528)', 'UPS(1Z9X66Y31352337152)', 'AMZN_US(TBA029357560801)', 'USPS(9361289701090493865417)', 'AMZN_US(TBA025274229601)', 'USPS(9400111899281881926605)', 'UPS(1Z9YF1891303497717)', 'UPS(1Z15998R0317190560)', 'AMZN_US(TBA036761141001)', 'USPS(9300120111404792467278)', 'AMZN_US(TBA040494227301)', 'AMZN_US(TBA040425385901)', 'UPS(1Z6A390F0305155610)', 'USPS(9361289701090506803542)', 'AMZN_US(TBA042754405201)', 'AMZN_US(TBA048869243901)', 'AMZN_US(TBA046900754401)', 'AMZN_US(TBA047003598901)', 'AMZN_US(TBA047539470101)', 'AMZN_US(TBA047397177101)', 'AMZN_US(TBA049654807601)', 'USPS(9305520111499570375787)', 'AMZN_US(TBA051188470701)', 'AMZN_US(TBA050967187101)', 'AMZN_US(TBA055193991901)', 'AMZN_US(TBA056700526901)', 'AMZN_US(TBA060878893201)', 'AMZN_US(TBA066703245001)', 'FedEx(394207454518)', 'UPS(1Z9X26970310004807)', 'USPS(9405510298370122363651)', 'AMZN_US(TBA072183268801)', 'AMZN_US(TBA071691520801)', 'AMZN_US(TBA072093653701)', 'USPS(9374889701090535310215)', 'AMZN_US(TBA077775691801)', 'FedEx(903208534149)', 'UPS(1Z6A390F0306442165)', 'AMZN_US(TBA079406043001)', 'AMZN_US(TBA079733507601)', 'AMZN_US(TBA080599805701)', 'AMZN_US(TBA083720446801)', 'USPS(9374889701090542394895)', 'AMZN_US(TBA084098201501)', 'AMZN_US(TBA083702459301)', 'AMZN_US(TBA086465706101)', 'AMZN_US(TBA086543390401)', 'AMZN_US(TBA086660823801)', 'UPS(1Z1480AE0380261162)', 'AMZN_US(TBA085293368301)', 'UPS(1Z1480AE0380317647)', 'AMZN_US(TBA084772312001)', 'AMZN_US(TBA085836370001)', 'AMZN_US(TBA087005072201)', 'USPS(9374889701090548052102)', 'AMZN_US(TBA089072160501)', 'AMZN_US(TBA089153895101)', 'AMZN_US(TBA089669511601)', 'AMZN_US(TBA089650464701)', 'AMZN_US(TBA089782605401)', 'AMZN_US(TBA090557303201)', 'USPS(9400111899563207215533)', 'AMZN_US(TBA090816293801)', 'AMZN_US(TBA091013887701)', 'AMZN_US(TBA092548962901)', 'AMZN_US(TBA100090152001)', 'AMZN_US(TBA105068839101)', '4PX(302781137668)', 'USPS(9400110298192008940919)', 'AMZN_US(TBA111091323401)', 'AMZN_US(TBA113765470601)', 'AMZN_US(TBA116003373701)', 'USPS(9374889701090584846741)', 'AMZN_US(TBA125223053701)', 'AMZN_US(TBA126398841501)', 'UPS(1Z6A390F0307838236)', 'AMZN_US(TBA129388416401)', 'USPS(9374889701090589027435)', 'USPS(9374889701090589226876)', 'USPS(9374889701090589246003)', 'AMZN_US(TBA132155339101)', 'USPS(9374889701090592769360)', 'USPS(9374889701090592349807)', 'USPS(9374889701090591642763)', 'USPS(9400110298192009246416)', 'USPS(9374889701090591799085)', 'UPS(1Z69VR561372467178)', 'USPS(9374889701090594651823)', 'UPS(1Z593Y0R0312416163)', 'AMZN_US(TBA145688704801)', 'AMZN_US(TBA145540727101)', 'USPS(9374889701090605090351)', 'AMZN_US(TBA000692045204)', 'AMZN_US(TBA147526077501)', 'AMZN_US(TBA000524310004)', 'AMZN_US(TBA003132328104)', 'USPS(9361289701090609529103)', 'FedEx(396946093833)', 'AMZN_US(TBA015010230904)', 'AMZN_US(TBA015581812604)', 'AMZN_US(TBA017345009204)', 'AMZN_US(TBA018351366504)', 'AMZN_US(TBA028638960104)', 'USPS(9405511202555702823996)', 'AMZN_US(TBA029468238304)', 'AMZN_US(TBA029696500904)', 'AMZN_US(TBA030751639804)', 'AMZN_US(TBA035539068004)', 'AMZN_US(TBA040471330604)', 'DHL Global Mail(420890159361269903505714542940)', 'AMZN_US(TBA038587859704)', 'AMZN_US(TBA041906295104)', 'AMZN_US(TBA043377022004)', 'AMZN_US(TBA044160327404)', 'AMZN_US(TBA044450021504)', 'USPS(9374889701090646225910)', 'AMZN_US(TBA066754205504)', 'AMZN_US(TBA067339747304)', 'AMZN_US(TBA066029544504)', 'AMZN_US(TBA070142657204)', 'AMZN_US(TBA069548946904)', 'AMZN_US(TBA070110653004)', 'AMZN_US(TBA071053531404)', 'AMZN_US(TBA070658997704)', 'Amazon(TBA071244976404)', 'UPS(1Z81WV730209855584)', 'AMZN_US(TBA071017664404)', 'AMZN_US(TBA072113924404)', 'USPS(9374889701090654584146)', 'AMZN_US(TBA092544601804)', 'AMZN_US(TBA093376155404)', 'AMZN_US(TBA093902303604)', 'AMZN_US(TBA094429025504)', 'AMZN_US(TBA113130056904)', 'AMZN_US(TBA116696148004)', 'USPS(9374889701090665921954)', 'AMZN_US(TBA119502153104)', 'UPS(1Z6A390F0310967573)', 'AMZN_US(TBA293359968000)', 'AMZN_US(TBA133884045604)', 'AMZN_US(TBA135218514604)', 'AMZN_US(TBA138334877704)', 'AMZN_US(TBA143484611204)', 'USPS(9374889701090675476208)', 'AMZN_US(TBA143177920404)', 'AMZN_US(TBA148077460904)', 'AMZN_US(TBA148849284004)', 'AMZN_US(TBA151651824204)', 'AMZN_US(TBA152068507004)', 'AMZN_US(TBA159036852304)', 'AMZN_US(TBA162569476304)', 'AMZN_US(TBA162698817204)', 'AMZN_US(TBA163221560904)', 'USPS(9374889701090682897980)', 'AMZN_US(TBA167442891204)', 'AMZN_US(TBA167240528904)', 'AMZN_US(TBA169378095004)', 'AMZN_US(TBA169252733804)', 'AMZN_US(TBA173620131004)', 'AMZN_US(TBA173843026204)', 'AMZN_US(TBA174771282404)', 'AMZN_US(TBA174695161104)', 'AMZN_US(TBA175364827004)', 'AMZN_US(TBA177943890704)', 'AMZN_US(TBA175751600104)', 'AMZN_US(TBA186135853704)', 'AMZN_US(TBA307903734000)', 'AMZN_US(TBA190040706504)', 'AMZN_US(TBA002918623804)', 'AMZN_US(TBA002387195304)', 'AMZN_US(TBA001571427404)', 'AMZN_US(TBA008564544104)', 'AMZN_US(TBA007051891204)', 'AMZN_US(TBA007099140204)', 'UPS(1Z6A390F0312665538)', 'AMZN_US(TBA016352822204)', 'AMZN_US(TBA317059549000)', 'DHL(420890159374869903506579219226)', 'UPS(1Z813R301315802704)', 'AMZN_US(TBA022380592304)', 'USPS(9405511108296502696476)', 'AMZN_US(TBA022059533404)', 'AMZN_US(TBA024483246504)', 'AMZN_US(TBA024758015804)', 'AMZN_US(TBA024583717004)', 'AMZN_US(TBA033854603104)', 'AMZN_US(TBA027400037204)', 'AMZN_US(TBA028597269104)', 'AMZN_US(TBA320364305000)', 'AMZN_US(TBA029276675404)', 'AMZN_US(TBA073275445404)', 'AMZN_US(TBA074528516004)', 'AMZN_US(TBA104805001204)', 'AMZN_US(TBA104938336804)', 'AMZN_US(TBA104969131104)', 'AMZN_US(TBA106180684204)', 'AMZN_US(TBA108139064004)', 'AMZN_US(TBA364242644000)', 'AMZN_US(TBA164889458504)', 'AMZN_US(TBA409211406000)', 'AMZN_US(TBA043054368404)', 'AMZN_US(TBA043527956804)', 'AMZN_US(TBA044328668404)', 'AMZN_US(TBA044438320304)', 'USPS(9374889701006743483641)', 'AMZN_US(TBA060629386304)', 'AMZN_US(TBA063020768904)', 'AMZN_US(TBA078948672604)', 'USPS(9374889701007777117380)', 'AMZN_US(TBA103348320004)', 'AMZN_US(TBA105350579504)', 'AMZN_US(TBA110573918804)', 'AMZN_US(TBA144061479304)', 'AMZN_US(TBA146091380304)', 'USPS(9374889701009200082036)', 'AMZN_US(TBA179779212004)', 'AMZN_US(TBA182502864104)', 'AMZN_US(TBA199220151504)', 'AMZN_US(TBA029565427704)', 'AMZN_US(TBA050665026904)', 'USPS(9374889701010608089831)', 'AMZN_US(TBA127094279804)', 'AMZN_US(TBA129611905004)', 'AMZN_US(TBA133380963204)', 'AMZN_US(TBA133446596504)', 'AMZN_US(TBA039295092104)', 'AMZN_US(TBA039767447804)', 'AMZN_US(TBA055755756304)', 'AMZN_US(TBA049317790304)', 'UPS(1Z82V7481340298048)', 'AMZN_US(TBA303310676561)', 'UPS(1Z9A403R0325831732)', 'AMZN_US(TBA303503759702)', 'AMZN_US(TBA777856753000)', 'AMZN_US(TBA779076924000)', 'AMZN_US(TBA303669955025)', 'UPS(1Z83797X0285719924)', 'AMZN_US(TBA304195520918)', 'AMZN_US(TBA304245182789)', 'AMZN_US(TBA304388656735)', 'AMZN_US(TBA304289237047)', 'AMZN_US(TBA304302031854)', 'AMZN_US(TBA304343019656)', 'AMZN_US(TBA304328384372)', 'UPS(1Z4E3W290315382658)', 'AMZN_US(TBA304641260603)', 'AMZN_US(TBA304730455450)', 'AMZN_US(TBA304713399048)', 'AMZN_US(TBA304723766586)', 'AMZN_US(TBA304834242476)', 'AMZN_US(TBA304889394828)', 'AMZN_US(TBA304966534152)', 'AMZN_US(TBA304960015006)', 'Yanwen(UG878348002YP)', 'AMZN_US(TBA305009967564)', 'AMZN_US(TBA305021479645)', 'USPS(9374889720118171897114)', 'AMZN_US(TBA305388485956)', 'SF Express(SF6043545498225)']\n",
    "print('%s shipping codes' % len(shipping_codes))\n",
    "print('%s unique Response Ids with shipping codes' % no_state_df[no_state_df['Shipping Address State'].isin(shipping_codes)]['Survey ResponseID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "18cb4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics for data before removing invalid states\n",
      "5254 response Ids\n",
      "1942117 total rows of data\n",
      "\n",
      "metrics after removing invalid states\n",
      "5254 response Ids\n",
      "1939873 total rows of data\n"
     ]
    }
   ],
   "source": [
    "print('metrics for data before removing invalid states')\n",
    "print_data_metrics(amzn_df)\n",
    "\n",
    "print('\\nmetrics after removing invalid states')\n",
    "amzn_df = amzn_df[(amzn_df['state'].notnull()) | amzn_df['Shipping Address State'].isna()]\n",
    "print_data_metrics(amzn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "42da03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Response IDs without any valid states\n",
      "Here is the distribution of how many rows of data they have\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      66.000000\n",
       "mean      443.484848\n",
       "std       660.169238\n",
       "min         1.000000\n",
       "25%        69.750000\n",
       "50%       275.500000\n",
       "75%       444.250000\n",
       "max      3207.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there responseIds where there are no US states in the data? Yes.\n",
    "\n",
    "no_states_response_ids_n = amzn_df['Survey ResponseID'].nunique() - amzn_df[amzn_df['state'].notnull()]['Survey ResponseID'].nunique()\n",
    "print('%s Response IDs without any valid states' % no_states_response_ids_n)\n",
    "# Get those Response IDs\n",
    "no_states_response_ids = list(set(amzn_df['Survey ResponseID'].unique()) - set(amzn_df[amzn_df['state'].notnull()]['Survey ResponseID'].unique()))\n",
    "\n",
    "# What does their data look like?\n",
    "# How much data?\n",
    "# After looking at this -- they might have just removed all address information and caught shipping state too\n",
    "# for i, rid in enumerate(no_states_response_ids):\n",
    "#     rdf = amzn_df[amzn_df['Survey ResponseID']==rid]\n",
    "#     print('%s - %s: %s rows of data' % (i, rid, len(rdf)))\n",
    "print('Here is the distribution of how many rows of data they have')\n",
    "no_states_response_ids_rows = [len(amzn_df[amzn_df['Survey ResponseID']==rid]) for rid in no_states_response_ids]\n",
    "pd.Series(no_states_response_ids_rows).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb04992",
   "metadata": {},
   "source": [
    "## Deduplicate Amazon data\n",
    "Collect duplicate response ids\n",
    "using initial rows of data from Jan 2018\n",
    "\n",
    "Methodology:\n",
    "- Note data are already clipped to starting after 1-1-2018\n",
    "- Get 1st X=5 (Order Date, ASIN) for each ResponseId --> concatenate to string as orders_string\n",
    "- Make map dedup_map: {orders_string: [ResponseId]} -- append to list if already there\n",
    "- dedup_map values which are lists of > 1 value show duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "22792ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Methodology notes\n",
    "\n",
    "Bad attempt v1: first tried this with just sorting on Order Date -- bad result:\n",
    "Number of unique order strings differs based on number of orders used\n",
    "5061 when orders=3 unique order strings; 5062 when orders=5; 5063 when orders=6; 5077 when orders=10\n",
    "Why the difference? Tested possible reasons: \n",
    "a. really different ppl with same initial orders\n",
    "b. there were < n_orders when initially did survey then did again after buying more stuff\n",
    "Real reason: \n",
    "When customers made multiple orders on the same day, the order of the items in the order history could vary\n",
    "This resulted in different order strings.\n",
    "\n",
    "Bad attempt v2: Just use first n product codes, sorted.\n",
    "More collisions with more orders, duh\n",
    "\n",
    "Bad attempt v2: Sort on both 'Order Date', 'ASIN/ISBN (Product Code)'\n",
    "Problem: Some product codes start with 0; in some cases this zero was excluded in downloaded data\n",
    "resulting in a different order string\n",
    "\n",
    "Solution that works: Sort on both 'Order Date', 'ASIN/ISBN (Product Code)', use last X digits.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# After much testing, this is what works, for reasons noted above.\n",
    "def get_orders_string(df, n_orders=5):\n",
    "    # example orders string: '2020-08-11:0IX1I3G6-2020-08-21:00WHXN3C-2020-08-21:074DJIUO-2020-08-21:07ZJV7TC-2020-08-21:0AXUCJP6'\n",
    "    # Using last X digits of product code\n",
    "    return '-'.join(\n",
    "        df[['Order Date', 'ASIN/ISBN (Product Code)']]\n",
    "        .sort_values(['Order Date', 'ASIN/ISBN (Product Code)']).head(n_orders).astype(str)\n",
    "        .apply(lambda x: ':'.join([x['Order Date'], x['ASIN/ISBN (Product Code)'][-8:]]), axis=1).to_list()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "438d4895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-11:0IX1I3G6-2020-08-21:00WHXN3C-2020-08-21:074DJIUO-2020-08-21:07ZJV7TC-2020-08-21:0AXUCJP6'"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_orders_string(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7e939eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Price Per Unit</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Shipping Address State</th>\n",
       "      <th>Title</th>\n",
       "      <th>ASIN/ISBN (Product Code)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Survey ResponseID</th>\n",
       "      <th>unit price</th>\n",
       "      <th>total price</th>\n",
       "      <th>yyyy-mm</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>$17.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Scott 1000 Sheets Per Roll Toilet Paper, 27 Ro...</td>\n",
       "      <td>B01NBYY28W</td>\n",
       "      <td>TOILET_PAPER</td>\n",
       "      <td>R_3pmMPapxGMCnM5y</td>\n",
       "      <td>17.52</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>$28.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>VIVA Choose-A-Sheet* Paper Towels, White, Big ...</td>\n",
       "      <td>B01LFFGW5K</td>\n",
       "      <td>PAPER_TOWEL</td>\n",
       "      <td>R_3pmMPapxGMCnM5y</td>\n",
       "      <td>28.99</td>\n",
       "      <td>28.99</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>$25.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Godel, Escher, Bach: An Eternal Golden Braid</td>\n",
       "      <td>0465026850</td>\n",
       "      <td>ABIS_BOOK</td>\n",
       "      <td>R_3pmMPapxGMCnM5y</td>\n",
       "      <td>25.38</td>\n",
       "      <td>25.38</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>$11.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Utopia Towels Soft Cotton Machine Washable, Ex...</td>\n",
       "      <td>B01DLD4YY0</td>\n",
       "      <td>TOWEL</td>\n",
       "      <td>R_3pmMPapxGMCnM5y</td>\n",
       "      <td>11.99</td>\n",
       "      <td>11.99</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>$86.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B06XC29HPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R_3pmMPapxGMCnM5y</td>\n",
       "      <td>86.66</td>\n",
       "      <td>86.66</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order Date Purchase Price Per Unit  Quantity Shipping Address State   \n",
       "0 2018-01-21                  $17.52       1.0                     NY  \\\n",
       "1 2018-01-21                  $28.99       1.0                     NY   \n",
       "2 2018-01-28                  $25.38       1.0                     NY   \n",
       "3 2018-03-04                  $11.99       1.0                     NY   \n",
       "4 2018-03-04                  $86.66       1.0                     NY   \n",
       "\n",
       "                                               Title ASIN/ISBN (Product Code)   \n",
       "0  Scott 1000 Sheets Per Roll Toilet Paper, 27 Ro...               B01NBYY28W  \\\n",
       "1  VIVA Choose-A-Sheet* Paper Towels, White, Big ...               B01LFFGW5K   \n",
       "2       Godel, Escher, Bach: An Eternal Golden Braid               0465026850   \n",
       "3  Utopia Towels Soft Cotton Machine Washable, Ex...               B01DLD4YY0   \n",
       "4                                                NaN               B06XC29HPY   \n",
       "\n",
       "       Category  Survey ResponseID  unit price  total price  yyyy-mm state  \n",
       "0  TOILET_PAPER  R_3pmMPapxGMCnM5y       17.52        17.52  2018-01    NY  \n",
       "1   PAPER_TOWEL  R_3pmMPapxGMCnM5y       28.99        28.99  2018-01    NY  \n",
       "2     ABIS_BOOK  R_3pmMPapxGMCnM5y       25.38        25.38  2018-01    NY  \n",
       "3         TOWEL  R_3pmMPapxGMCnM5y       11.99        11.99  2018-03    NY  \n",
       "4           NaN  R_3pmMPapxGMCnM5y       86.66        86.66  2018-03    NY  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This was me. I tested multiple times with my own data.\n",
    "# Found during dedup process.\n",
    "amzn_df[amzn_df['Survey ResponseID']=='R_3pmMPapxGMCnM5y'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "84762acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0: 2023-04-23 13:59:02.949943\n",
      "i=500: 2023-04-23 13:59:27.020088\n",
      "i=1000: 2023-04-23 13:59:51.392118\n",
      "i=1500: 2023-04-23 14:00:16.004254\n",
      "i=2000: 2023-04-23 14:00:40.555973\n",
      "i=2500: 2023-04-23 14:01:04.982048\n",
      "i=3000: 2023-04-23 14:01:29.454378\n",
      "i=3500: 2023-04-23 14:01:53.856107\n",
      "i=4000: 2023-04-23 14:02:18.274911\n",
      "i=4500: 2023-04-23 14:02:42.731963\n",
      "i=5000: 2023-04-23 14:03:07.223436\n"
     ]
    }
   ],
   "source": [
    "n_orders=5\n",
    "dedup_map = dict()\n",
    "dup_count = 0\n",
    "response_ids = amzn_df['Survey ResponseID'].unique()\n",
    "for i, rid in enumerate(response_ids):\n",
    "    if i%500 == 0:\n",
    "        print('i=%s: %s' % (i, pd.Timestamp.now()))\n",
    "    rdf = amzn_df[amzn_df['Survey ResponseID']==rid]\n",
    "    orders_string = get_orders_string(rdf, n_orders=n_orders)\n",
    "    if orders_string in dedup_map:\n",
    "        dedup_map[orders_string] += [(rid, len(rdf))]\n",
    "        dup_count += 1\n",
    "        continue\n",
    "    dedup_map[orders_string] = [(rid, len(rdf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "8b25b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5054 unique order strings\n",
      "vs 5254 unique response Ids\n",
      "= 200 duplicate responses\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dedup map looks like this\n",
    "{'0140502017-0873516095-193938012X-B004S7EZR0-B00DGYHIMU': [('R_3I9Pu8iauEcOx9A', 127)], \n",
    "'B00KVL0SIM-B01LYOCVZF-B01NAJGGA2-B07585JXNZ-B07B41717Z': [('R_7UtikIBqeQHvnyN', 53)], \n",
    "...}\n",
    "\"\"\"\n",
    "print('%s unique order strings' % len(dedup_map))\n",
    "print('vs %s unique response Ids' % len(response_ids))\n",
    "print('= %s duplicate responses' % (dup_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "48cfef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0: 2023-04-23 14:04:05.649727: 1\n",
      "i=500: 2023-04-23 14:04:07.790638: 1\n",
      "i=1000: 2023-04-23 14:04:09.649859: 1\n",
      "i=1500: 2023-04-23 14:04:11.461137: 1\n",
      "i=2000: 2023-04-23 14:04:13.223879: 1\n",
      "i=2500: 2023-04-23 14:04:14.913610: 1\n",
      "i=3000: 2023-04-23 14:04:17.849260: 1\n",
      "i=3500: 2023-04-23 14:04:19.997409: 1\n",
      "i=4000: 2023-04-23 14:04:21.609771: 1\n",
      "i=4500: 2023-04-23 14:04:23.567915: 1\n",
      "i=5000: 2023-04-23 14:04:24.641705: 1\n"
     ]
    }
   ],
   "source": [
    "# Would there be fewer dups if we used more orders? Test dups again with 10\n",
    "dedup_map10 = dict()\n",
    "dup_count10 = 0\n",
    "for i, (_orders_string5, rids) in enumerate(dedup_map.items()):\n",
    "    if i%500 == 0:\n",
    "        print('i=%s: %s: %s' % (i, pd.Timestamp.now(), len(rids)))\n",
    "    if len(rids) < 2:\n",
    "        continue\n",
    "    for (rid, _n) in rids:\n",
    "        rdf = amzn_df[amzn_df['Survey ResponseID']==rid]\n",
    "        orders_string10 = get_orders_string(rdf, n_orders=10)\n",
    "        if orders_string10 in dedup_map10:\n",
    "            dedup_map10[orders_string10] += [(rid, len(rdf))]\n",
    "            dup_count10 += 1\n",
    "            continue\n",
    "        dedup_map10[orders_string10] = [(rid, len(rdf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "7abfd08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs 199 duplicate responses\n"
     ]
    }
   ],
   "source": [
    "print('vs %s duplicate responses' % dup_count10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "ad10e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the difference\n",
    "diff_dups = dict()\n",
    "m = 0\n",
    "for orders_string5, rids5 in dedup_map.items():\n",
    "    # find the corresponding orders string (n=10)\n",
    "    for orders_string10, rids10 in dedup_map10.items():\n",
    "        if orders_string10.startswith(orders_string5):\n",
    "            m += 1\n",
    "            if len(rids5) != len(rids10):\n",
    "                if orders_string5 not in diff_dups:\n",
    "                    diff_dups[orders_string5] = dict()\n",
    "                diff_dups[orders_string5][orders_string10] = rids10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175a369",
   "metadata": {},
   "source": [
    "Here we see only difference is due to one string being longer than the other (more orders).\n",
    "\n",
    "So use dedup_map with n_orders=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "7f73c0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2018-03-31:07BLNK6C-2018-03-31:0XAF0AIE-2018-05-21:74F2K187-2018-05-21:74T9LMC2-2018-06-10:00YB70PS': {'2018-03-31:07BLNK6C-2018-03-31:0XAF0AIE-2018-05-21:74F2K187-2018-05-21:74T9LMC2-2018-06-10:00YB70PS-2018-06-17:00YB70PS': [('R_3HFzy82OvxJnm7L',\n",
       "    6)],\n",
       "  '2018-03-31:07BLNK6C-2018-03-31:0XAF0AIE-2018-05-21:74F2K187-2018-05-21:74T9LMC2-2018-06-10:00YB70PS-2018-06-17:00YB70PS-2018-09-02:1IWM70JQ-2018-11-05:7CP99SBT-2018-11-05:7DLSQFL8-2018-11-20:6XVZ6F2C': [('R_3EF584Zf9pAwkir',\n",
       "    201)]}}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1de20",
   "metadata": {},
   "source": [
    "Collect the list of response ids to drop vs keep from the duplicates lists.\n",
    "\n",
    "How to choose?\n",
    "Keep the ones with the most data. Take the first if they're the same.\n",
    "Where Most data: Most rows with no nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "0d705963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "drop_rids = []\n",
    "for _i, (_orders_string, rids) in enumerate(dedup_map.items()):\n",
    "    if len(rids) > 1:\n",
    "        keep_rid = None\n",
    "        most_rows = 0\n",
    "        for (rid, _n) in rids:\n",
    "            notna_rows = len(amzn_df[amzn_df['Survey ResponseID']==rid].dropna())\n",
    "            if notna_rows >= most_rows: # some have nan state in all rows and will hence have notna_rows = 0 -- keep\n",
    "                most_rows = notna_rows\n",
    "                if keep_rid is not None:\n",
    "                    drop_rids += [keep_rid]\n",
    "                keep_rid = rid\n",
    "            else:\n",
    "                drop_rids += [rid]\n",
    "\n",
    "print(len(drop_rids))\n",
    "# drop_rids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "95c0749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_responseids = drop_rids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c92e6",
   "metadata": {},
   "source": [
    "### Drop Amazon data from duplicate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "e964e0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicate Amazon data:\n",
      "1939873 rows of Amazon data\n",
      "5254 unique response ids\n"
     ]
    }
   ],
   "source": [
    "print('Before dropping duplicate Amazon data:')\n",
    "print('%s rows of Amazon data' % len(amzn_df))\n",
    "print('%s unique response ids' % amzn_df['Survey ResponseID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "356d4091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicate Amazon data:\n",
      "1860434 rows of Amazon data\n",
      "5054 unique response ids\n"
     ]
    }
   ],
   "source": [
    "amzn_df = amzn_df[~amzn_df['Survey ResponseID'].isin(drop_responseids)]\n",
    "print('Before dropping duplicate Amazon data:')\n",
    "print('%s rows of Amazon data' % len(amzn_df))\n",
    "print('%s unique response ids' % amzn_df['Survey ResponseID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838efc02",
   "metadata": {},
   "source": [
    "## Process Survey Data\n",
    "\n",
    "Output: processed survey data (can be used on its own)\n",
    "- Restrict to valid worker/Prolific IDs\n",
    "- Deduplicate on worker/Prolific IDs\n",
    "- Join the 2 survey datasets\n",
    "- Remove data where 'test' is indicated\n",
    "- Remove rows with bad ResponseIds (from step 1)\n",
    "- Make public\n",
    "    - separate comments\n",
    "    - remove worker/Prolific IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "8d977153",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_unprocessed_fpath = '../data/survey-data/unprocessed/'\n",
    "v0_survey_unprocessed_fpath = survey_unprocessed_fpath + 'v0.csv'\n",
    "cloudresearch_survey_unprocessed_fpath = survey_unprocessed_fpath + 'v-cloudresearch.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a29eda",
   "metadata": {},
   "source": [
    "### Deduplicate Cloudresearch survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "6610a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793 rows of data before preprocessing\n",
      "removing duplicate worker IDs -- keeping last\n",
      "792 rows of data\n"
     ]
    }
   ],
   "source": [
    "cloudresearch_survey_df = pd.read_csv(cloudresearch_survey_unprocessed_fpath)\n",
    "# first rows is fields/description of columns\n",
    "print('%s rows of data before preprocessing' % len(cloudresearch_survey_df.drop([0])))\n",
    "print('removing duplicate worker IDs -- keeping last')\n",
    "cloudresearch_survey_df = cloudresearch_survey_df.drop_duplicates(\n",
    "    subset='Q-workerId', keep='last')\n",
    "print('%s rows of data' % len(cloudresearch_survey_df.drop([0])))\n",
    "# cloudresearch_survey_df.drop([0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66f55e",
   "metadata": {},
   "source": [
    "### Deduplicate v0/Prolific survey data\n",
    "\n",
    "- Survey was initially used in mturk\n",
    "- Did not collect mturk worker IDs, instead gave mturk workers a random code upon completion\n",
    "- No reason to believe possible for duplicate submissions under a single mturk worker ID\n",
    "- There may have been duplicate Prolific IDs in responses -- find and remove those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "fba259bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5733 rows of data before preprocessing\n"
     ]
    }
   ],
   "source": [
    "v0_survey_df = pd.read_csv(v0_survey_unprocessed_fpath)\n",
    "# first rows is fields/description of columns\n",
    "print('%s rows of data before preprocessing' % len(v0_survey_df.drop([0])))\n",
    "# Find and remove any duplicate Prolific IDs\n",
    "# Get rows with non-na Prolific IDs; find duplicates, keep last\n",
    "# v0_survey_df.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "ad58e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5704 Prolific ID entries\n",
      "Dropping 15 duplicates\n",
      "5718 remaining rows of data\n"
     ]
    }
   ],
   "source": [
    "prolific_ids = v0_survey_df['Q-prolific'].dropna()\n",
    "print('%s Prolific ID entries' % len(prolific_ids))\n",
    "# prolific_ids\n",
    "# Duplicate entries are here:\n",
    "# prolific_ids[prolific_ids.duplicated(keep='last')].index\n",
    "print('Dropping %s duplicates' % prolific_ids.duplicated(keep='last').sum())\n",
    "v0_survey_df = v0_survey_df.drop(prolific_ids[prolific_ids.duplicated(keep='last')].index)\n",
    "print('%s remaining rows of data' % len(v0_survey_df.drop([0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcccf5e",
   "metadata": {},
   "source": [
    "### Merge survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e688922",
   "metadata": {},
   "source": [
    "#### First save the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "3c291ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved fields to file ../data/survey-data/fields.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <td>Duration (in seconds)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordedDate</th>\n",
       "      <td>Recorded Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResponseId</th>\n",
       "      <td>Response ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-prolific</th>\n",
       "      <td>What is your Prolific ID?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-prolific-mturk</th>\n",
       "      <td>Do you also complete surveys (or HITs) using A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q-demos-age</th>\n",
       "      <td>What is your age group?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-hispanic</th>\n",
       "      <td>Are you of Spanish, Hispanic, or Latino origin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-race</th>\n",
       "      <td>Choose one or more races that you consider you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-education</th>\n",
       "      <td>What is the highest level of education you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-income</th>\n",
       "      <td>What was your total household income before ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-gender</th>\n",
       "      <td>How do you describe yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-sexual-orientation</th>\n",
       "      <td>Which best describes your sexual orientation?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-demos-state</th>\n",
       "      <td>50 States, D.C. and Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-amazon-use-howmany</th>\n",
       "      <td>How many people do you share your Amazon accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-amazon-use-hh-size</th>\n",
       "      <td>How many people are in your \"household\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-amazon-use-how-oft</th>\n",
       "      <td>How often do you (+ anyone you share your acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-substance-use_1</th>\n",
       "      <td>Are any of the following the case for:\\n\\nYou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-substance-use_2</th>\n",
       "      <td>Are any of the following the case for:\\n\\nYou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-substance-use_3</th>\n",
       "      <td>Are any of the following the case for:\\n\\nYou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-personal_1</th>\n",
       "      <td>Are any of the following the case for:\\n\\nYou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-personal_2</th>\n",
       "      <td>Are any of the following the case for:\\n\\nYou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-life-changes</th>\n",
       "      <td>In 2021 did you, or someone you share your Ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-control</th>\n",
       "      <td>Click to insert the file from Amazon below.\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-altruism</th>\n",
       "      <td>Click to insert the file from Amazon below.\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-bonus-05</th>\n",
       "      <td>Click to insert the file from Amazon below.\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-bonus-20</th>\n",
       "      <td>Click to insert the file from Amazon below.\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-bonus-50</th>\n",
       "      <td>Click to insert the file from Amazon below.\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-05</th>\n",
       "      <td>Would you hypothetically consent to share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-20</th>\n",
       "      <td>Would you hypothetically consent to share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-50</th>\n",
       "      <td>Would you hypothetically consent to share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-100</th>\n",
       "      <td>Would you hypothetically consent to share your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-any</th>\n",
       "      <td>How much would you share your data for? - Sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-data-value-any_1_TEXT</th>\n",
       "      <td>How much would you share your data for? - More...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-sell-YOUR-data</th>\n",
       "      <td>Do you think Amazon should be able to sell YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-sell-consumer-data</th>\n",
       "      <td>Do you think companies should be able to sell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-small-biz-use</th>\n",
       "      <td>Big companies currently collect and sell consu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-census-use</th>\n",
       "      <td>Do you think the U.S. Census Bureau should use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-research-society</th>\n",
       "      <td>Do you think researchers should be able to use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-attn-check</th>\n",
       "      <td>This is an attention check. Help us find peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-comments</th>\n",
       "      <td>Comments? (optional)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResponseID</th>\n",
       "      <td>ResponseID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>showdata</th>\n",
       "      <td>showdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incentive</th>\n",
       "      <td>incentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q-workerId</th>\n",
       "      <td>What is your Worker ID?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connect</th>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    fields\n",
       "Duration (in seconds)                                Duration (in seconds)\n",
       "RecordedDate                                                 Recorded Date\n",
       "ResponseId                                                     Response ID\n",
       "Q-prolific                                       What is your Prolific ID?\n",
       "Q-prolific-mturk         Do you also complete surveys (or HITs) using A...\n",
       "q-demos-age                                        What is your age group?\n",
       "Q-demos-hispanic           Are you of Spanish, Hispanic, or Latino origin?\n",
       "Q-demos-race             Choose one or more races that you consider you...\n",
       "Q-demos-education        What is the highest level of education you hav...\n",
       "Q-demos-income           What was your total household income before ta...\n",
       "Q-demos-gender                               How do you describe yourself?\n",
       "Q-sexual-orientation         Which best describes your sexual orientation?\n",
       "Q-demos-state                              50 States, D.C. and Puerto Rico\n",
       "Q-amazon-use-howmany     How many people do you share your Amazon accou...\n",
       "Q-amazon-use-hh-size              How many people are in your \"household\"?\n",
       "Q-amazon-use-how-oft     How often do you (+ anyone you share your acco...\n",
       "Q-substance-use_1        Are any of the following the case for:\\n\\nYou ...\n",
       "Q-substance-use_2        Are any of the following the case for:\\n\\nYou ...\n",
       "Q-substance-use_3        Are any of the following the case for:\\n\\nYou ...\n",
       "Q-personal_1             Are any of the following the case for:\\n\\nYou ...\n",
       "Q-personal_2             Are any of the following the case for:\\n\\nYou ...\n",
       "Q-life-changes           In 2021 did you, or someone you share your Ama...\n",
       "Q-control                Click to insert the file from Amazon below.\\n ...\n",
       "Q-altruism               Click to insert the file from Amazon below.\\n ...\n",
       "Q-bonus-05               Click to insert the file from Amazon below.\\n ...\n",
       "Q-bonus-20               Click to insert the file from Amazon below.\\n ...\n",
       "Q-bonus-50               Click to insert the file from Amazon below.\\n ...\n",
       "Q-data-value-05          Would you hypothetically consent to share your...\n",
       "Q-data-value-20          Would you hypothetically consent to share your...\n",
       "Q-data-value-50          Would you hypothetically consent to share your...\n",
       "Q-data-value-100         Would you hypothetically consent to share your...\n",
       "Q-data-value-any         How much would you share your data for? - Sele...\n",
       "Q-data-value-any_1_TEXT  How much would you share your data for? - More...\n",
       "Q-sell-YOUR-data         Do you think Amazon should be able to sell YOU...\n",
       "Q-sell-consumer-data     Do you think companies should be able to sell ...\n",
       "Q-small-biz-use          Big companies currently collect and sell consu...\n",
       "Q-census-use             Do you think the U.S. Census Bureau should use...\n",
       "Q-research-society       Do you think researchers should be able to use...\n",
       "Q-attn-check             This is an attention check. Help us find peopl...\n",
       "Q-comments                                            Comments? (optional)\n",
       "ResponseID                                                      ResponseID\n",
       "showdata                                                          showdata\n",
       "incentive                                                        incentive\n",
       "Q-workerId                                         What is your Worker ID?\n",
       "connect                                                            connect"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_fpath = '../data/survey-data/fields.csv'\n",
    "\n",
    "cloudresearch_fields = cloudresearch_survey_df.loc[0].rename('fields').to_frame()\n",
    "v0_fields = v0_survey_df.loc[0].rename('fields').to_frame()\n",
    "v0_fields.loc['Q-workerId'] = cloudresearch_fields.loc['Q-workerId'] #'What is your Worker ID?'\n",
    "v0_fields.loc['connect'] = cloudresearch_fields.loc['connect'] # Embedded data\n",
    "v0_fields.to_csv(fields_fpath)\n",
    "print('saved fields to file %s' % fields_fpath)\n",
    "v0_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25489da7",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "f29513b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expect 6510 rows after concatenating\n"
     ]
    }
   ],
   "source": [
    "print('Expect %s rows after concatenating' % \n",
    "      (len(v0_survey_df.drop(0)) + len(cloudresearch_survey_df.drop(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "e3fb0b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510 rows from merged data\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "survey_df = pd.concat(\n",
    "    [v0_survey_df.drop(0), cloudresearch_survey_df.drop(0)], \n",
    "    ignore_index=True # Otherwise have duplicate index values\n",
    ")\n",
    "print('%s rows from merged data' % len(survey_df))\n",
    "# survey_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8f652",
   "metadata": {},
   "source": [
    "#### Remove test data\n",
    "\n",
    "Remove any rows where test is in the worker/Prolific ID or comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "11e2eef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>Q-prolific</th>\n",
       "      <th>Q-prolific-mturk</th>\n",
       "      <th>q-demos-age</th>\n",
       "      <th>Q-demos-hispanic</th>\n",
       "      <th>Q-demos-race</th>\n",
       "      <th>Q-demos-education</th>\n",
       "      <th>Q-demos-income</th>\n",
       "      <th>...</th>\n",
       "      <th>Q-small-biz-use</th>\n",
       "      <th>Q-census-use</th>\n",
       "      <th>Q-research-society</th>\n",
       "      <th>Q-attn-check</th>\n",
       "      <th>Q-comments</th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>showdata</th>\n",
       "      <th>incentive</th>\n",
       "      <th>Q-workerId</th>\n",
       "      <th>connect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>192</td>\n",
       "      <td>10/4/2022 8:30:11</td>\n",
       "      <td>R_PBTmuy6D8TQbN97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 - 34 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Some high school or less</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>...</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>test by alex for pilot-3 (did BATCH stick?)</td>\n",
       "      <td>R_PBTmuy6D8TQbN97</td>\n",
       "      <td>false</td>\n",
       "      <td>altruism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>188</td>\n",
       "      <td>10/4/2022 8:30:36</td>\n",
       "      <td>R_2whJTuUcscZje1i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 - 34 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>TEST RM</td>\n",
       "      <td>R_2whJTuUcscZje1i</td>\n",
       "      <td>true</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>799</td>\n",
       "      <td>10/11/2022 11:04:24</td>\n",
       "      <td>R_2ZD2bHi2XkFFA4D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35 - 44 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>...</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>I don't know</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>TEST ANDY</td>\n",
       "      <td>R_2ZD2bHi2XkFFA4D</td>\n",
       "      <td>true</td>\n",
       "      <td>bonus-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>1212</td>\n",
       "      <td>4/16/2023 0:25:05</td>\n",
       "      <td>R_YWhHGZNwr5aUuRP</td>\n",
       "      <td>test</td>\n",
       "      <td>No</td>\n",
       "      <td>18 - 24 years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R_YWhHGZNwr5aUuRP</td>\n",
       "      <td>false</td>\n",
       "      <td>bonus-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Duration (in seconds)         RecordedDate         ResponseId Q-prolific   \n",
       "23                     192    10/4/2022 8:30:11  R_PBTmuy6D8TQbN97        NaN  \\\n",
       "24                     188    10/4/2022 8:30:36  R_2whJTuUcscZje1i        NaN   \n",
       "25                     799  10/11/2022 11:04:24  R_2ZD2bHi2XkFFA4D        NaN   \n",
       "5717                  1212    4/16/2023 0:25:05  R_YWhHGZNwr5aUuRP       test   \n",
       "\n",
       "     Q-prolific-mturk    q-demos-age Q-demos-hispanic        Q-demos-race   \n",
       "23                NaN  25 - 34 years               No  White or Caucasian  \\\n",
       "24                NaN  25 - 34 years               No  White or Caucasian   \n",
       "25                NaN  35 - 44 years               No  White or Caucasian   \n",
       "5717               No  18 - 24 years              Yes  White or Caucasian   \n",
       "\n",
       "                                      Q-demos-education     Q-demos-income   \n",
       "23                             Some high school or less   $150,000 or more  \\\n",
       "24    Graduate or professional degree (MA, MS, MBA, ...  $25,000 - $49,999   \n",
       "25                                    Prefer not to say  Prefer not to say   \n",
       "5717  Graduate or professional degree (MA, MS, MBA, ...  $25,000 - $49,999   \n",
       "\n",
       "      ... Q-small-biz-use  Q-census-use Q-research-society   \n",
       "23    ...    I don't know  I don't know                 No  \\\n",
       "24    ...             Yes           Yes                Yes   \n",
       "25    ...    I don't know  I don't know       I don't know   \n",
       "5717  ...              No            No                Yes   \n",
       "\n",
       "             Q-attn-check                                   Q-comments   \n",
       "23    Yes,No,I don't know  test by alex for pilot-3 (did BATCH stick?)  \\\n",
       "24    Yes,No,I don't know                                      TEST RM   \n",
       "25    Yes,No,I don't know                                    TEST ANDY   \n",
       "5717  Yes,No,I don't know                                          NaN   \n",
       "\n",
       "             ResponseID showdata incentive Q-workerId connect  \n",
       "23    R_PBTmuy6D8TQbN97    false  altruism        NaN     NaN  \n",
       "24    R_2whJTuUcscZje1i     true   control        NaN     NaN  \n",
       "25    R_2ZD2bHi2XkFFA4D     true  bonus-20        NaN     NaN  \n",
       "5717  R_YWhHGZNwr5aUuRP    false  bonus-05        NaN     NaN  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = survey_df[\n",
    "    survey_df['Q-prolific'].apply(lambda pid: 'test' in str(pid)) \\\n",
    "    | survey_df['Q-workerId'].apply(lambda wid: 'test' in str(wid)) \\\n",
    "    | survey_df['Q-comments'].apply(lambda c: (len(str(c)) < 50) and ('test' in str(c).lower()))\n",
    "]\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "e9cea15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6506 rows after dropping tests\n"
     ]
    }
   ],
   "source": [
    "survey_df = survey_df.drop(tests.index)\n",
    "print('%s rows after dropping tests' % len(survey_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4a1f8",
   "metadata": {},
   "source": [
    "### Remove duplicate responses based on Amazon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "42decabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 200 response ids to drop from Amazon data\n",
      "181 to be dropped from survey response data\n"
     ]
    }
   ],
   "source": [
    "print('found %s response ids to drop from Amazon data' % len(drop_responseids))\n",
    "print('%s to be dropped from survey response data' % survey_df['ResponseId'].isin(drop_responseids).sum())\n",
    "survey_df = survey_df[~survey_df['ResponseId'].isin(drop_responseids)]\n",
    "# drop_responseids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "4345449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6325 remaining survey data rows\n"
     ]
    }
   ],
   "source": [
    "print('%s remaining survey data rows' % len(survey_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "21bc568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the ResponseId and embedded data ResponseID are the same\n",
    "assert(0 == len(survey_df[survey_df['ResponseId'] != survey_df['ResponseID']]))\n",
    "# And drop extra column for ResponseID\n",
    "survey_df = survey_df.drop('ResponseID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5fc12",
   "metadata": {},
   "source": [
    "### Handle comments\n",
    "\n",
    "As per the IRB protocol, separate the comments from the rest of the response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "4dcdd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738 comments\n",
      "saving comments without response id and with different index to ../data/survey-data/comments.csv\n",
      "dropping comments from survey data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great study!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       comments\n",
       "0  Great study!\n",
       "1    none today\n",
       "2   good survey\n",
       "3           aaa\n",
       "4       Thanks!"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_fpath = '../data/survey-data/comments.csv'\n",
    "\n",
    "comments = survey_df['Q-comments'].rename('comments').dropna().reset_index(drop=True).to_frame()\n",
    "print('%s comments' % len(comments))\n",
    "print('saving comments without response id and with different index to %s' % comments_fpath)\n",
    "comments.to_csv(comments_fpath, index=False)\n",
    "print('dropping comments from survey data')\n",
    "survey_df = survey_df.drop('Q-comments', axis=1)\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85239cd5",
   "metadata": {},
   "source": [
    "### Prepare the survey data to make publicly available\n",
    "\n",
    "Drop worker/Prolific ID.\n",
    "Drop extra metadata ResponseID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "c82c10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 6325 rows of survey data to ../data/survey-data/survey.csv\n"
     ]
    }
   ],
   "source": [
    "processed_survey_fpath = '../data/survey-data/survey.csv'\n",
    "survey_df = survey_df.drop(['Q-prolific', 'Q-workerId'], axis=1)\n",
    "print('saving %s rows of survey data to %s' % (len(survey_df), processed_survey_fpath))\n",
    "survey_df.to_csv(processed_survey_fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "ba85fa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>Q-prolific-mturk</th>\n",
       "      <th>q-demos-age</th>\n",
       "      <th>Q-demos-hispanic</th>\n",
       "      <th>Q-demos-race</th>\n",
       "      <th>Q-demos-education</th>\n",
       "      <th>Q-demos-income</th>\n",
       "      <th>Q-demos-gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Q-data-value-any_1_TEXT</th>\n",
       "      <th>Q-sell-YOUR-data</th>\n",
       "      <th>Q-sell-consumer-data</th>\n",
       "      <th>Q-small-biz-use</th>\n",
       "      <th>Q-census-use</th>\n",
       "      <th>Q-research-society</th>\n",
       "      <th>Q-attn-check</th>\n",
       "      <th>showdata</th>\n",
       "      <th>incentive</th>\n",
       "      <th>connect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332</td>\n",
       "      <td>9/21/2022 10:00:17</td>\n",
       "      <td>R_1ou69fj4DQGsVcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35 - 44 years</td>\n",
       "      <td>No</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>False</td>\n",
       "      <td>bonus-50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>9/21/2022 10:02:24</td>\n",
       "      <td>R_24dboHVOzohx1kw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 - 34 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes if I get part of the profit</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>False</td>\n",
       "      <td>bonus-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>9/21/2022 10:10:47</td>\n",
       "      <td>R_2UbJL30HRjK1sdD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45 - 54 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>$100,000 - $149,999</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>False</td>\n",
       "      <td>bonus-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339</td>\n",
       "      <td>9/21/2022 10:13:03</td>\n",
       "      <td>R_UPXamGKtmf4RVIZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 - 34 years</td>\n",
       "      <td>No</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>High school diploma or GED</td>\n",
       "      <td>$25,000 - $49,999</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>False</td>\n",
       "      <td>bonus-50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674</td>\n",
       "      <td>9/21/2022 11:36:51</td>\n",
       "      <td>R_2dYk5auG9Fv5Qve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35 - 44 years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Graduate or professional degree (MA, MS, MBA, ...</td>\n",
       "      <td>$50,000 - $74,999</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes,No,I don't know</td>\n",
       "      <td>True</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration (in seconds)        RecordedDate         ResponseId   \n",
       "0                    332  9/21/2022 10:00:17  R_1ou69fj4DQGsVcp  \\\n",
       "1                    488  9/21/2022 10:02:24  R_24dboHVOzohx1kw   \n",
       "2                    309  9/21/2022 10:10:47  R_2UbJL30HRjK1sdD   \n",
       "3                    339  9/21/2022 10:13:03  R_UPXamGKtmf4RVIZ   \n",
       "4                    674  9/21/2022 11:36:51  R_2dYk5auG9Fv5Qve   \n",
       "\n",
       "  Q-prolific-mturk    q-demos-age Q-demos-hispanic               Q-demos-race   \n",
       "0              NaN  35 - 44 years               No  Black or African American  \\\n",
       "1              NaN  25 - 34 years               No         White or Caucasian   \n",
       "2              NaN  45 - 54 years               No         White or Caucasian   \n",
       "3              NaN  25 - 34 years               No         White or Caucasian   \n",
       "4              NaN  35 - 44 years              Yes         White or Caucasian   \n",
       "\n",
       "                                   Q-demos-education       Q-demos-income   \n",
       "0                         High school diploma or GED    $25,000 - $49,999  \\\n",
       "1                                  Bachelor's degree    $25,000 - $49,999   \n",
       "2                         High school diploma or GED  $100,000 - $149,999   \n",
       "3                         High school diploma or GED    $25,000 - $49,999   \n",
       "4  Graduate or professional degree (MA, MS, MBA, ...    $50,000 - $74,999   \n",
       "\n",
       "  Q-demos-gender  ... Q-data-value-any_1_TEXT   \n",
       "0         Female  ...                     NaN  \\\n",
       "1           Male  ...                     NaN   \n",
       "2           Male  ...                     NaN   \n",
       "3           Male  ...                     NaN   \n",
       "4           Male  ...                     NaN   \n",
       "\n",
       "                  Q-sell-YOUR-data Q-sell-consumer-data Q-small-biz-use   \n",
       "0                               No                   No              No  \\\n",
       "1  Yes if I get part of the profit                  Yes              No   \n",
       "2                               No                   No              No   \n",
       "3                               No                   No              No   \n",
       "4                               No                   No              No   \n",
       "\n",
       "  Q-census-use Q-research-society         Q-attn-check showdata incentive   \n",
       "0           No                 No  Yes,No,I don't know    False  bonus-50  \\\n",
       "1          Yes                Yes  Yes,No,I don't know    False  bonus-05   \n",
       "2           No                Yes  Yes,No,I don't know    False  bonus-05   \n",
       "3           No                Yes  Yes,No,I don't know    False  bonus-50   \n",
       "4           No                 No  Yes,No,I don't know     True   control   \n",
       "\n",
       "  connect  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df = pd.read_csv(processed_survey_fpath)\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472eff60",
   "metadata": {},
   "source": [
    "## Output cleaned Amazon data\n",
    "\n",
    "Remove any rows without a corresponding Response id in survey data.\n",
    "- Due to dropping duplicates and tests from survey data\n",
    "- Due to incomplete responses\n",
    "- Due to failed attention checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "88fe74e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6325 survey response ids\n",
      "5054 unique response ids in Amazon data\n",
      "5027 unique response ids in both amazon data and survey data\n",
      "dropping Amazon data without corresponding responseId in survey data\n",
      "1850717 total Amazon data rows\n"
     ]
    }
   ],
   "source": [
    "survey_response_ids = survey_df['ResponseId']\n",
    "print('%s survey response ids' % len(survey_response_ids))\n",
    "assert(len(survey_response_ids) == survey_df['ResponseId'].nunique())\n",
    "print('%s unique response ids in Amazon data' % amzn_df['Survey ResponseID'].nunique())\n",
    "print('%s unique response ids in both amazon data and survey data' % (\n",
    "    amzn_df[amzn_df['Survey ResponseID'].isin(survey_response_ids)]['Survey ResponseID'].nunique()))\n",
    "\n",
    "# Drop Amazon data that does not have a correponding responseId in survey data\n",
    "print('dropping Amazon data without corresponding responseId in survey data')\n",
    "amzn_df = amzn_df[amzn_df['Survey ResponseID'].isin(survey_response_ids)]\n",
    "print('%s total Amazon data rows' % len(amzn_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "53000010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving cleaned amazon data to ../data/amazon-data/amazon-data-cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_amz_data_fpath = '../data/amazon-data/amazon-data-cleaned.csv'\n",
    "print('saving cleaned amazon data to %s' % cleaned_amz_data_fpath)\n",
    "amzn_df.to_csv(cleaned_amz_data_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca957a30",
   "metadata": {},
   "source": [
    "Data links for restricted access data\n",
    "\n",
    "(Permissioned to people with approvals)\n",
    "\n",
    "- [Survey comments](https://drive.google.com/file/d/1E3o9-rYRvf0ZYRzMYXUhJ8PVeVztcen2/view?usp=share_link)\n",
    "- [Amazon data](https://drive.google.com/file/d/12Od0Rl6zVPecrAOlH9JEIuyKeQixFYno/view?usp=share_link)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-amazon-study",
   "language": "python",
   "name": "venv-amazon-study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
